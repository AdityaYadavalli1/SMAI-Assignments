{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "The objective of this assignment is to get you familiarizewith  the  problems  of  `classification`  and  `verification`with a popular problem space of `face`\n",
    "\n",
    "This jupyter notebook is meant to be used in conjunction with the full questions in the assignment pdf.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analyses in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of the other cells.\n",
    "\n",
    "## Allowed Libraries\n",
    "- All libraries are allowed \n",
    "\n",
    "## Datasets \n",
    "- 3 datasets are provided. Load the data from the drive [link](!https://drive.google.com/file/d/1ujsKv9W5eidb4TXt1pnsqwDKVDFtzZTh/view?usp=sharing).\n",
    "- Unzip the downloaded file and store the files in a folder called `datasets`. Keep the `datasets` folder in the same directory as of the jupyter notebook \n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>.ipynb` and submit ONLY the notebook file on moodle.\n",
    "- Upload  the  notebook,  report  and  classification  results as a zip file to moodle. Name the zip file as `<rollnumber>_assignment2.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (0.21.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.1.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/site-packages (6.2.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/adityayadavalli/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/adityayadavalli/Library/Python/3.7/lib/python/site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing Libraries\n",
    "!pip install scikit-learn matplotlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "\n",
    "# Loading and plotting data\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import _class_means,_class_cov\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "- Image size: Bigger images create better representation but would require more computation. Choose the correct image size based on your Laptop configuration. \n",
    "- is_grayscale: Should you take grayscale images? Or rgb images? Choose whichever gives better representation for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'image_size': 32,\n",
    "    'is_grayscale': True,\n",
    "    'val_split': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "cfw_dict = {'Amitabhbachan': 0,\n",
    "    'AamirKhan': 1,\n",
    "    'DwayneJohnson': 2,\n",
    "    'AishwaryaRai': 3,\n",
    "    'BarackObama': 4,\n",
    "    'NarendraModi': 5,\n",
    "    'ManmohanSingh': 6,\n",
    "    'VladimirPutin': 7}\n",
    "\n",
    "imfdb_dict = {'MadhuriDixit': 0,\n",
    "     'Kajol': 1,\n",
    "     'SharukhKhan': 2,\n",
    "     'ShilpaShetty': 3,\n",
    "     'AmitabhBachan': 4,\n",
    "     'KatrinaKaif': 5,\n",
    "     'AkshayKumar': 6,\n",
    "     'Amir': 7}\n",
    "\n",
    "# Load Image using PIL for dataset\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n",
    "    im = im.resize((opt['image_size'],opt['image_size']))\n",
    "    im = np.array(im)\n",
    "    im = im/256\n",
    "    return im\n",
    "\n",
    "# Load the full data from directory\n",
    "def load_data(dir_path):\n",
    "    image_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if \"CFW\" in dir_path:\n",
    "        label_dict = cfw_dict\n",
    "\n",
    "    elif \"yale\" in dir_path.lower():\n",
    "        label_dict = {}\n",
    "        for i in range(15):\n",
    "            label_dict[str(i+1)] = i\n",
    "    elif \"IMFDB\" in dir_path:\n",
    "        label_dict = imfdb_dict\n",
    "    else:\n",
    "        raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "    for filename in sorted(os.listdir(dir_path)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            im = load_image(os.path.join(dir_path,filename))\n",
    "            y = filename.split('_')[0]\n",
    "            y = label_dict[y] \n",
    "            image_list.append(im)\n",
    "            y_list.append(y)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    print(\"Dataset shape:\",image_list.shape)\n",
    "\n",
    "    return image_list,y_list\n",
    "\n",
    "# Display N Images in a nice format\n",
    "def disply_images(imgs,classes,row=1,col=2,w=64,h=64):\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, col*row +1):\n",
    "        img = imgs[i-1]\n",
    "        fig.add_subplot(row, col, i)\n",
    "        \n",
    "        if opt['is_grayscale']:\n",
    "            plt.imshow(img , cmap='gray') \n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        \n",
    "        plt.title(\"Class:{}\".format(classes[i-1]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# eg.\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y.shape[0],6)\n",
    "disply_images(X[ind,...],y[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X_1,y_1 = load_data(dirpath)\n",
    "N_1,H_1,W_1 = X_1.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X_1.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y_1.shape[0],6)\n",
    "disply_images(X_1[ind,...],y_1[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "dirpath = './dataset/Yale_face_database/'\n",
    "X_2,y_2 = load_data(dirpath)\n",
    "N_2,H_2,W_2 = X_2.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X_2.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y_2.shape[0],6)\n",
    "disply_images(X_2[ind,...],y_2[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "    You are provided 6 Features. These features are:\n",
    "   - Eigen Faces / PCA \n",
    "   - Kernel PCA\n",
    "   - Fisher Face / LDA\n",
    "   - Kernel Fisher Face\n",
    "   - VGG Features \n",
    "   - Resnet Features\n",
    "\n",
    "**VGG and Resnet features are last layer features learned by training a model for image classification**\n",
    "    \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Flatten to apply PCA/LDA\n",
    "X = X.reshape((N,H*W*C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = X_1.reshape((N_1,H_1*W_1*C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = X_2.reshape((N_2,H_2*W_2*C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Eigen Face:\n",
    "Use principal component analysis to get the eigen faces. \n",
    "Go through the [documentation](!http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) on how to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X,k):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=k)\n",
    "    X_k = pca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Kernel Face:\n",
    "Use Kernel principal component analysis to get the eigen faces. \n",
    "\n",
    "There are different kernels that can be used. Eg. Poly, rbf, sigmoid. Choose the whichever gives the best result or representation. See [link](!https://data-flair.training/blogs/svm-kernel-functions/) for better understanding of these kernels  \n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_pca(X, k,kernel='rbf', degree=3):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use (linear | poly | rbf | sigmoid | cosine )\n",
    "        @param: d => Degree for poly kernels. Ignored by other kernels\n",
    "    \"\"\"\n",
    "    kpca = KernelPCA(n_components=k,kernel=kernel,degree=degree)\n",
    "    X_k = kpca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fisher Face\n",
    "Another method similar to the eigenface technique is `fisherfaces` which uses linear discriminant analysis.\n",
    "This method for facial recognition is less sensitive to variation in lighting and pose of the face than using eigenfaces. Fisherface uses labelled data to retain more of the class-specific information during the dimension reduction stage.\n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda(X,y, k):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "    \"\"\"\n",
    "    lda = LDA(n_components=k)\n",
    "    X_k = lda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kernel Fisher Face\n",
    "Use LDA using different kernels similiar to KernelPCA. Here the input is directly transformed instead of using the kernel trick.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_lda(X,y,k,kernel='rbf',degree=3):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use ( poly | rbf | sigmoid)\n",
    "    \"\"\"\n",
    "    # Transform  input\n",
    "    if kernel == \"poly\":\n",
    "        X_transformed = X**degree\n",
    "    elif kernel == \"rbf\":\n",
    "        var = np.var(X)\n",
    "        X_transformed= np.exp(-X/(2*var))\n",
    "    elif kernel == \"sigmoid\":\n",
    "        X_transformed = np.tanh(X)\n",
    "    else: \n",
    "        raise NotImplementedError(\"Kernel {} Not defined\".format(kernel))\n",
    "        \n",
    "    klda = LDA(n_components=k)\n",
    "    X_k = klda.fit_transform(X_transformed,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. VGG Features\n",
    "VGG Neural Networks a 19 layer CNN architecture introduced by Andrew Zisserman([Link](!https://arxiv.org/pdf/1409.1556.pdf) to paper). We are providing you with the last fully connected layer of this model.\n",
    "\n",
    "The model was trained for face classification on each dataset and each feature the dimension of 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"VGG19_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resnet Features\n",
    "\n",
    "[Residual neural networks](!https://arxiv.org/pdf/1512.03385.pdf) are CNN with large depth, to effectively train these netwrorks they utilize skip connections, or short-cuts to jump over some layers. This helps solving [vanishing gradient problem](!https://en.wikipedia.org/wiki/Vanishing_gradient_problem) \n",
    "\n",
    "A 50 layer resnet model was trained for face classification on each dataset. Each feature the dimension of 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"resnet50_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1(a). What are eigen faces? \n",
    "\n",
    "___________________________\n",
    "\n",
    "Your answers here (double click to edit)\n",
    "Eigenfaces is a name given to eigenvectors in the domain of computer vision. These can help us know to what dimension we can reduce the image so that we can compress but at the same time not reduce its quality significantly.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b). How many eigen vectors/faces are required to satisfactorily reconstruct a  person  in  these  three  datasets? (Dont  forget  to make your argument based on eigen value spectrum) Show appropriate graphs, qualitative examples and make a convincing argument.\n",
    "\n",
    "## IMFDB \n",
    "Number of eigenvectors is around 108. \n",
    "## IIIT-CFW\n",
    "Number of eigenvectors is around 309.\n",
    "## Yale Face Database \n",
    "Number of eigenvectors is around 62.\n",
    "\n",
    "I have plotted the spectrum for reference. One can notice that there is a significant drop (and the rest are almost negligible) at the above mentioned numbers. I have taken the threshold value as 0.95 for eigenvalues selected divided by total eigenvalues.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n",
      "(400, 32, 32)\n",
      "(1024, 1024)\n",
      "1024\n",
      "(400, 108)\n"
     ]
    }
   ],
   "source": [
    "# Compute your features \n",
    "# eg.\n",
    "# X_3D = get_kernel_lda(X,y,3)\n",
    "#loading dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "print(np.shape(X))\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "cov = np.cov(X.T) #check \n",
    "print(np.shape(cov))\n",
    "eigvals, eigvectors = np.linalg.eig(cov) \n",
    "# print(np.shape(eigvals))\n",
    "s_vals = eigvals[:2]\n",
    "s_vecs = eigvectors[:, :2]\n",
    "print(X.shape[1])\n",
    "X_k = np.dot(s_vecs.T, X.T).T\n",
    "# print(X_k)\n",
    "# for i in range(X.shape[1]):\n",
    "#     s_vals = eigvals[:i]\n",
    "#     s_vecs = eigvectors[:, :i]\n",
    "#     X_k = np.dot(s_vecs.T, X.T).T\n",
    "#     print(i, np.sum(s_vals)/full)  #check explained_variance_\n",
    "    \n",
    "s_vals = eigvals[:108]\n",
    "s_vecs = eigvectors[:, :108]\n",
    "X_k = np.dot(s_vecs.T, X.T).T\n",
    "print(np.shape(X_k))\n",
    "#X = get_pca(X, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "(672, 32, 32)\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X_1,y_1 = load_data(dirpath)\n",
    "N,H,W = X_1.shape[0:3]\n",
    "print(np.shape(X_1))\n",
    "C = 1 if opt['is_grayscale'] else X_1.shape[3]\n",
    "X_1 = X_1.reshape((N,H*W*C))\n",
    "print(X_1.shape[1])\n",
    "cov_1 = np.cov(X_1.T) #check \n",
    "# print(np.shape(cov_1))\n",
    "eigvals_1, eigvectors_1 = np.linalg.eig(cov_1) \n",
    "full_1 = np.sum(np.real(eigvals_1))\n",
    "# for i in range(X_1.shape[1]):\n",
    "#     s_vals_1 = eigvals_1[:i]\n",
    "#     s_vecs_1 = eigvectors_1[:, :i]\n",
    "#     X_k_1 = np.dot(s_vecs_1.T, X_1.T).T\n",
    "#     print(i, np.sum(np.real(s_vals_1))/full_1) \n",
    "\n",
    "s_vals_1 = eigvals_1[:309]\n",
    "s_vecs_1 = eigvectors_1[:, :309]\n",
    "\n",
    "X_k_1 = np.dot(s_vecs_1.T, X_1.T).T\n",
    "# print(np.shape(X_k_1))\n",
    "# magic number 309\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n",
      "(165, 32, 32)\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "dirpath = './dataset/Yale_face_database/'\n",
    "X_2,y_2 = load_data(dirpath)\n",
    "print(np.shape(X_2))\n",
    "N,H,W = X_2.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X_2.shape[3]\n",
    "X_2 = X_2.reshape((N,H*W*C))\n",
    "print(X_2.shape[1])\n",
    "cov_2 = np.cov(X_2.T) #check \n",
    "# print(np.shape(cov))\n",
    "eigvals_2, eigvectors_2 = np.linalg.eig(cov_2) \n",
    "full_2 = np.sum(np.real(eigvals_2))\n",
    "# for i in range(X_2.shape[1]):\n",
    "#     s_vals_2 = eigvals_2[:i]\n",
    "#     s_vecs_2 = eigvectors_2[:, :i]\n",
    "#     X_k_2 = np.dot(s_vecs_2.T, X_2.T).T\n",
    "#     print(i, np.sum(np.real(s_vals_2))/full_2) \n",
    "\n",
    "s_vals_2 = eigvals_2[:62]\n",
    "s_vecs_2 = eigvectors_2[:, :62]\n",
    "\n",
    "X_k_2 = np.dot(s_vecs_2.T, X_2.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x122352be0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot  \n",
    "# eg.\n",
    "print(np.shape(np.real(X_k[:,0])))\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(np.real(X_k[:,0]),np.real(X_k[:,1]), np.real(X_k[:,2]), c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the eigen value spectrum \n",
    "# s_vals = eigvals[:1024]\n",
    "# s_vecs = eigvectors[:, :1024]\n",
    "X_k = np.dot(eigvals.T, X.T).T\n",
    "plt.plot(np.real(eigvals))\n",
    "\n",
    "s_vals = eigvals[:108]\n",
    "s_vecs = eigvectors[:, :108]\n",
    "X_k = np.dot(s_vecs.T, X.T).T\n",
    "# need for next cell. Perfect dimension to reduce is 108. It is above 95% \n",
    "# pca = get_pca(X, 109) \n",
    "# X_k = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.shape(X_1))\n",
    "# s_vals_1 = eigvals_1[:3072]\n",
    "# s_vecs_1 = eigvectors_1[:, :3072]\n",
    "X_k_1 = np.dot(eigvals_1.T, X_1.T).T\n",
    "plt.plot(np.real(eigvals_1))\n",
    "\n",
    "s_vals_1 = eigvals_1[:309]\n",
    "s_vecs_1 = eigvectors_1[:, :309]\n",
    "X_k_1 = np.dot(s_vecs_1.T, X_1.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.shape(X_2))\n",
    "s_vals_2 = eigvals_2[:3072]\n",
    "s_vecs_2 = eigvectors_1[:, :3072]\n",
    "X_k_2 = np.dot(s_vecs_2.T, X_2.T).T\n",
    "plt.plot(np.real(s_vals_2))\n",
    "\n",
    "s_vals_2 = eigvals_2[:62]\n",
    "s_vecs_2 = eigvectors_2[:, :62]\n",
    "X_k_2 = np.dot(s_vecs_2.T, X_2.T).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c). Reconstruct  the  image  back for each case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(eigenvectors, X_k):\n",
    "    \"\"\"\n",
    "        Reconstruct the images back by just using the selected principal components. \n",
    "\n",
    "\n",
    "        You have to write the code in this code block.\n",
    "        You can change the functions provided above (eg, get_pca, get_lda) for your use case. \n",
    "            \n",
    "        @params: \n",
    "                Input parameters\n",
    "\n",
    "        @return reconstructed_X => reconstructed image\n",
    "        \n",
    "    \"\"\"\n",
    "#     reconstruct_X = pca.inverse_transform(X_k)\n",
    "#     data_recovered = NP.dot(eigenvectors, m).T\n",
    "    reconstruct_X = np.dot(eigenvectors, X_k).T\n",
    "    \n",
    "    return reconstruct_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04023024649167747+0j)\n"
     ]
    }
   ],
   "source": [
    "# Display results \n",
    "X_reconstructed = reconstruct_images(s_vecs, X_k.T)\n",
    "# print(np.shape(X_reconstructed))\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X[ind,...],y[ind], row=2,col=3)\n",
    "\n",
    "# Display random images\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X_reconstruced[ind,...],y[ind],row=2,col=3)\n",
    "\n",
    "# Show the reconstruction error\n",
    "print(np.sqrt(np.mean((X - X_reconstructed)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06426838393868956+0j)\n"
     ]
    }
   ],
   "source": [
    "X_reconstructed_1 = reconstruct_images(s_vecs_1, X_k_1.T)\n",
    "# print(np.shape(X_reconstructed))\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X[ind,...],y[ind], row=2,col=3)\n",
    "\n",
    "# Display random images\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X_reconstruced[ind,...],y[ind],row=2,col=3)\n",
    "\n",
    "# Show the reconstruction error\n",
    "print(np.sqrt(np.mean((X_1 - X_reconstructed_1)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1404954791875422+0j)\n"
     ]
    }
   ],
   "source": [
    "X_reconstructed_2 = reconstruct_images(s_vecs_2, X_k_2.T)\n",
    "# print(np.shape(X_reconstructed))\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X[ind,...],y[ind], row=2,col=3)\n",
    "\n",
    "# Display random images\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X_reconstruced[ind,...],y[ind],row=2,col=3)\n",
    "\n",
    "# Show the reconstruction error\n",
    "print(np.sqrt(np.mean((X_2 - X_reconstructed_2)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(d). Which person/identity is difficult to represent compactly with fewer eigen vectors?  Why is that?  Explain with your empirical observations and intuitive answers\n",
    "\n",
    "## IMFDB \n",
    "Madhuri is the most difficult person to respresent with fewer eigenvectors when compared with others. She probably has complex facial faetures which needs more eigenvectors to express/represent. \n",
    "## IIIT-CFW \n",
    "Man Mohan Singh is the most difficult person to respresent with fewer eigenvectors when compared with others. He probably has complex facial faetures which needs more eigenvectors to express/represent.  \n",
    "## Yale Face Database\n",
    "Class 0 is slightly harder to represent with fewer eigenvectors when compared with others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.31288278671044584\n",
      "2 0.5086565911628431\n",
      "3 0.5748757737665025\n",
      "4 0.621901605705424\n",
      "5 0.6613370934687506\n",
      "6 0.6968738096012744\n",
      "7 0.7264557101359318\n",
      "8 0.7484319724674158\n",
      "9 0.7679471447777764\n",
      "10 0.7869483633992991\n",
      "11 0.8030909171074972\n",
      "12 0.8189228665636609\n",
      "13 0.8333543772952953\n",
      "14 0.8455246293389287\n",
      "15 0.85645273730406\n",
      "16 0.8666644896677393\n",
      "17 0.8758900799916857\n",
      "18 0.8849153360652053\n",
      "19 0.8937770751164552\n",
      "20 0.901876095246447\n",
      "21 0.9092515802061025\n",
      "22 0.916434302133607\n",
      "23 0.9227451281192337\n",
      "24 0.9288523194506099\n",
      "25 0.934435120701657\n",
      "26 0.9396461969272812\n",
      "27 0.9447232515660019\n",
      "28 0.9497139692435792\n",
      "29 0.9539681352720928\n",
      "30 0.9580505087197453\n",
      "31 0.9619146894590285\n",
      "32 0.9655166608906035\n",
      "33 0.9688783706613393\n",
      "34 0.971997793300752\n",
      "35 0.9749861494108122\n",
      "36 0.9778042726151789\n",
      "37 0.9804588639290271\n",
      "38 0.9828618362715785\n",
      "39 0.9850991338178583\n",
      "40 0.987305375368058\n",
      "41 0.9893146386601869\n",
      "42 0.9910588141783474\n",
      "43 0.992724769087147\n",
      "44 0.9942101933309001\n",
      "45 0.9956519171059189\n",
      "46 0.9968910311057779\n",
      "47 0.9980200360521428\n",
      "48 0.9991745013842027\n",
      "49 0.9999999999999998\n",
      "50 0.9999999999999998\n",
      "51 0.9999999999999998\n",
      "52 0.9999999999999998\n",
      "53 0.9999999999999998\n",
      "54 0.9999999999999998\n",
      "55 0.9999999999999998\n",
      "56 0.9999999999999998\n",
      "57 0.9999999999999998\n",
      "58 0.9999999999999998\n",
      "59 0.9999999999999998\n",
      "60 0.9999999999999998\n",
      "61 0.9999999999999998\n",
      "62 0.9999999999999998\n",
      "63 0.9999999999999998\n",
      "64 0.9999999999999998\n",
      "65 0.9999999999999998\n",
      "66 0.9999999999999998\n",
      "67 0.9999999999999998\n",
      "68 0.9999999999999998\n",
      "69 0.9999999999999998\n",
      "70 0.9999999999999998\n",
      "71 0.9999999999999998\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 0.9999999999999998\n",
      "97 0.9999999999999998\n",
      "98 0.9999999999999998\n",
      "99 0.9999999999999998\n",
      "100 0.9999999999999998\n",
      "101 0.9999999999999998\n",
      "102 0.9999999999999998\n",
      "103 0.9999999999999998\n",
      "104 0.9999999999999998\n",
      "105 0.9999999999999998\n",
      "106 0.9999999999999998\n",
      "107 0.9999999999999998\n",
      "108 0.9999999999999998\n",
      "109 0.9999999999999998\n",
      "110 0.9999999999999998\n",
      "111 0.9999999999999998\n",
      "112 0.9999999999999998\n",
      "113 0.9999999999999998\n",
      "114 0.9999999999999998\n",
      "115 0.9999999999999998\n",
      "116 0.9999999999999998\n",
      "117 0.9999999999999998\n",
      "118 0.9999999999999998\n",
      "119 0.9999999999999998\n",
      "120 0.9999999999999998\n",
      "121 0.9999999999999998\n",
      "122 0.9999999999999998\n",
      "123 0.9999999999999998\n",
      "124 0.9999999999999998\n",
      "125 0.9999999999999998\n",
      "126 0.9999999999999998\n",
      "127 0.9999999999999998\n",
      "128 0.9999999999999998\n",
      "129 0.9999999999999998\n",
      "130 0.9999999999999998\n",
      "131 0.9999999999999996\n",
      "132 0.9999999999999996\n",
      "133 0.9999999999999996\n",
      "134 0.9999999999999996\n",
      "135 0.9999999999999996\n",
      "136 0.9999999999999996\n",
      "137 0.9999999999999996\n",
      "138 0.9999999999999996\n",
      "139 0.9999999999999996\n",
      "140 0.9999999999999996\n",
      "141 0.9999999999999998\n",
      "142 0.9999999999999998\n",
      "143 0.9999999999999998\n",
      "144 0.9999999999999998\n",
      "145 0.9999999999999998\n",
      "146 0.9999999999999998\n",
      "147 0.9999999999999998\n",
      "148 0.9999999999999998\n",
      "149 0.9999999999999998\n",
      "150 0.9999999999999998\n",
      "151 1.0\n",
      "152 1.0\n",
      "153 1.0\n",
      "154 1.0\n",
      "155 1.0\n",
      "156 1.0\n",
      "157 1.0\n",
      "158 1.0\n",
      "159 1.0\n",
      "160 0.9999999999999998\n",
      "161 0.9999999999999998\n",
      "162 1.0\n",
      "163 1.0\n",
      "164 1.0\n",
      "165 1.0\n",
      "166 1.0\n",
      "167 1.0\n",
      "168 1.0\n",
      "169 1.0\n",
      "170 1.0\n",
      "171 1.0\n",
      "172 1.0\n",
      "173 1.0\n",
      "174 1.0\n",
      "175 1.0\n",
      "176 1.0\n",
      "177 1.0\n",
      "178 1.0\n",
      "179 1.0\n",
      "180 1.0\n",
      "181 1.0\n",
      "182 1.0\n",
      "183 1.0\n",
      "184 1.0\n",
      "185 1.0\n",
      "186 1.0\n",
      "187 1.0\n",
      "188 1.0\n",
      "189 1.0\n",
      "190 1.0\n",
      "191 1.0\n",
      "192 0.9999999999999998\n",
      "193 0.9999999999999998\n",
      "194 0.9999999999999998\n",
      "195 0.9999999999999998\n",
      "196 0.9999999999999998\n",
      "197 0.9999999999999998\n",
      "198 0.9999999999999998\n",
      "199 0.9999999999999998\n",
      "200 0.9999999999999998\n",
      "201 0.9999999999999998\n",
      "202 0.9999999999999998\n",
      "203 0.9999999999999998\n",
      "204 0.9999999999999998\n",
      "205 0.9999999999999998\n",
      "206 0.9999999999999998\n",
      "207 0.9999999999999998\n",
      "208 0.9999999999999998\n",
      "209 0.9999999999999998\n",
      "210 0.9999999999999998\n",
      "211 0.9999999999999998\n",
      "212 0.9999999999999998\n",
      "213 0.9999999999999998\n",
      "214 0.9999999999999998\n",
      "215 0.9999999999999998\n",
      "216 0.9999999999999998\n",
      "217 0.9999999999999998\n",
      "218 0.9999999999999998\n",
      "219 0.9999999999999998\n",
      "220 0.9999999999999998\n",
      "221 0.9999999999999998\n",
      "222 0.9999999999999998\n",
      "223 0.9999999999999998\n",
      "224 0.9999999999999998\n",
      "225 0.9999999999999998\n",
      "226 0.9999999999999998\n",
      "227 0.9999999999999998\n",
      "228 0.9999999999999998\n",
      "229 0.9999999999999998\n",
      "230 0.9999999999999998\n",
      "231 0.9999999999999998\n",
      "232 0.9999999999999998\n",
      "233 0.9999999999999998\n",
      "234 0.9999999999999998\n",
      "235 0.9999999999999998\n",
      "236 0.9999999999999998\n",
      "237 0.9999999999999998\n",
      "238 0.9999999999999998\n",
      "239 0.9999999999999998\n",
      "240 1.0\n",
      "241 1.0\n",
      "242 1.0\n",
      "243 1.0\n",
      "244 1.0\n",
      "245 1.0\n",
      "246 1.0\n",
      "247 1.0\n",
      "248 1.0\n",
      "249 1.0\n",
      "250 0.9999999999999998\n",
      "251 0.9999999999999998\n",
      "252 0.9999999999999998\n",
      "253 0.9999999999999998\n",
      "254 0.9999999999999998\n",
      "255 0.9999999999999998\n",
      "256 1.0\n",
      "257 0.9999999999999998\n",
      "258 0.9999999999999998\n",
      "259 0.9999999999999998\n",
      "260 0.9999999999999998\n",
      "261 0.9999999999999998\n",
      "262 0.9999999999999998\n",
      "263 0.9999999999999998\n",
      "264 0.9999999999999998\n",
      "265 0.9999999999999998\n",
      "266 0.9999999999999998\n",
      "267 0.9999999999999998\n",
      "268 0.9999999999999998\n",
      "269 0.9999999999999998\n",
      "270 0.9999999999999998\n",
      "271 0.9999999999999998\n",
      "272 0.9999999999999998\n",
      "273 0.9999999999999998\n",
      "274 0.9999999999999998\n",
      "275 0.9999999999999998\n",
      "276 0.9999999999999998\n",
      "277 0.9999999999999998\n",
      "278 0.9999999999999998\n",
      "279 0.9999999999999998\n",
      "280 0.9999999999999998\n",
      "281 0.9999999999999998\n",
      "282 0.9999999999999998\n",
      "283 0.9999999999999998\n",
      "284 0.9999999999999998\n",
      "285 0.9999999999999998\n",
      "286 0.9999999999999998\n",
      "287 0.9999999999999998\n",
      "288 0.9999999999999998\n",
      "289 0.9999999999999998\n",
      "290 0.9999999999999998\n",
      "291 0.9999999999999998\n",
      "292 0.9999999999999998\n",
      "293 0.9999999999999998\n",
      "294 0.9999999999999998\n",
      "295 0.9999999999999998\n",
      "296 0.9999999999999998\n",
      "297 0.9999999999999998\n",
      "298 0.9999999999999998\n",
      "299 0.9999999999999998\n",
      "300 0.9999999999999998\n",
      "301 0.9999999999999998\n",
      "302 0.9999999999999998\n",
      "303 0.9999999999999998\n",
      "304 1.0\n",
      "305 1.0\n",
      "306 1.0\n",
      "307 1.0\n",
      "308 1.0\n",
      "309 1.0\n",
      "310 1.0\n",
      "311 1.0\n",
      "312 1.0\n",
      "313 1.0\n",
      "314 1.0\n",
      "315 1.0\n",
      "316 1.0\n",
      "317 1.0\n",
      "318 1.0\n",
      "319 1.0\n",
      "320 0.9999999999999998\n",
      "321 0.9999999999999998\n",
      "322 0.9999999999999998\n",
      "323 0.9999999999999998\n",
      "324 0.9999999999999998\n",
      "325 0.9999999999999998\n",
      "326 0.9999999999999998\n",
      "327 0.9999999999999998\n",
      "328 0.9999999999999998\n",
      "329 0.9999999999999998\n",
      "330 0.9999999999999998\n",
      "331 0.9999999999999998\n",
      "332 0.9999999999999998\n",
      "333 0.9999999999999998\n",
      "334 0.9999999999999998\n",
      "335 0.9999999999999998\n",
      "336 1.0\n",
      "337 1.0\n",
      "338 1.0\n",
      "339 1.0\n",
      "340 1.0\n",
      "341 1.0\n",
      "342 1.0\n",
      "343 1.0\n",
      "344 1.0\n",
      "345 1.0\n",
      "346 1.0\n",
      "347 1.0\n",
      "348 1.0\n",
      "349 1.0\n",
      "350 1.0\n",
      "351 1.0\n",
      "352 1.0\n",
      "353 1.0\n",
      "354 1.0\n",
      "355 1.0\n",
      "356 1.0\n",
      "357 1.0\n",
      "358 1.0\n",
      "359 1.0\n",
      "360 1.0\n",
      "361 1.0\n",
      "362 1.0\n",
      "363 1.0\n",
      "364 1.0\n",
      "365 1.0\n",
      "366 1.0\n",
      "367 1.0\n",
      "368 1.0\n",
      "369 1.0\n",
      "370 1.0\n",
      "371 1.0\n",
      "372 1.0\n",
      "373 1.0\n",
      "374 1.0\n",
      "375 1.0\n",
      "376 1.0\n",
      "377 1.0\n",
      "378 1.0\n",
      "379 1.0\n",
      "380 1.0\n",
      "381 1.0\n",
      "382 1.0\n",
      "383 1.0\n",
      "384 0.9999999999999998\n",
      "385 0.9999999999999998\n",
      "386 0.9999999999999998\n",
      "387 0.9999999999999998\n",
      "388 0.9999999999999998\n",
      "389 0.9999999999999998\n",
      "390 0.9999999999999998\n",
      "391 0.9999999999999998\n",
      "392 0.9999999999999998\n",
      "393 0.9999999999999998\n",
      "394 0.9999999999999998\n",
      "395 0.9999999999999998\n",
      "396 0.9999999999999998\n",
      "397 0.9999999999999998\n",
      "398 0.9999999999999998\n",
      "399 0.9999999999999998\n",
      "400 0.9999999999999998\n",
      "401 0.9999999999999998\n",
      "402 0.9999999999999998\n",
      "403 0.9999999999999998\n",
      "404 0.9999999999999998\n",
      "405 0.9999999999999998\n",
      "406 0.9999999999999998\n",
      "407 0.9999999999999998\n",
      "408 0.9999999999999998\n",
      "409 0.9999999999999998\n",
      "410 0.9999999999999998\n",
      "411 0.9999999999999998\n",
      "412 0.9999999999999998\n",
      "413 0.9999999999999998\n",
      "414 0.9999999999999998\n",
      "415 0.9999999999999998\n",
      "416 0.9999999999999998\n",
      "417 0.9999999999999998\n",
      "418 0.9999999999999998\n",
      "419 0.9999999999999998\n",
      "420 0.9999999999999998\n",
      "421 0.9999999999999998\n",
      "422 0.9999999999999998\n",
      "423 0.9999999999999998\n",
      "424 0.9999999999999998\n",
      "425 0.9999999999999998\n",
      "426 0.9999999999999998\n",
      "427 0.9999999999999998\n",
      "428 0.9999999999999998\n",
      "429 0.9999999999999998\n",
      "430 0.9999999999999998\n",
      "431 0.9999999999999998\n",
      "432 0.9999999999999998\n",
      "433 0.9999999999999998\n",
      "434 0.9999999999999998\n",
      "435 0.9999999999999998\n",
      "436 0.9999999999999998\n",
      "437 0.9999999999999998\n",
      "438 0.9999999999999998\n",
      "439 0.9999999999999998\n",
      "440 0.9999999999999998\n",
      "441 0.9999999999999998\n",
      "442 0.9999999999999998\n",
      "443 0.9999999999999998\n",
      "444 0.9999999999999998\n",
      "445 0.9999999999999998\n",
      "446 0.9999999999999998\n",
      "447 0.9999999999999998\n",
      "448 0.9999999999999998\n",
      "449 0.9999999999999998\n",
      "450 0.9999999999999998\n",
      "451 0.9999999999999998\n",
      "452 0.9999999999999998\n",
      "453 0.9999999999999998\n",
      "454 0.9999999999999998\n",
      "455 0.9999999999999998\n",
      "456 0.9999999999999998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457 0.9999999999999998\n",
      "458 0.9999999999999998\n",
      "459 0.9999999999999998\n",
      "460 0.9999999999999998\n",
      "461 0.9999999999999998\n",
      "462 0.9999999999999998\n",
      "463 0.9999999999999998\n",
      "464 0.9999999999999998\n",
      "465 0.9999999999999998\n",
      "466 0.9999999999999998\n",
      "467 0.9999999999999998\n",
      "468 0.9999999999999998\n",
      "469 0.9999999999999998\n",
      "470 0.9999999999999998\n",
      "471 0.9999999999999998\n",
      "472 0.9999999999999998\n",
      "473 0.9999999999999998\n",
      "474 0.9999999999999998\n",
      "475 0.9999999999999998\n",
      "476 0.9999999999999998\n",
      "477 0.9999999999999998\n",
      "478 0.9999999999999998\n",
      "479 0.9999999999999998\n",
      "480 1.0\n",
      "481 1.0\n",
      "482 1.0\n",
      "483 1.0\n",
      "484 1.0\n",
      "485 1.0\n",
      "486 1.0\n",
      "487 1.0\n",
      "488 1.0\n",
      "489 1.0\n",
      "490 1.0\n",
      "491 1.0\n",
      "492 1.0\n",
      "493 1.0\n",
      "494 1.0\n",
      "495 1.0\n",
      "496 1.0\n",
      "497 1.0\n",
      "498 1.0\n",
      "499 1.0\n",
      "500 1.0\n",
      "501 1.0\n",
      "502 1.0\n",
      "503 1.0\n",
      "504 1.0\n",
      "505 1.0\n",
      "506 1.0\n",
      "507 1.0\n",
      "508 1.0\n",
      "509 1.0\n",
      "510 1.0\n",
      "511 1.0\n",
      "512 1.0\n",
      "513 1.0\n",
      "514 1.0\n",
      "515 1.0\n",
      "516 1.0\n",
      "517 1.0\n",
      "518 1.0\n",
      "519 1.0\n",
      "520 1.0\n",
      "521 1.0\n",
      "522 1.0\n",
      "523 1.0\n",
      "524 1.0\n",
      "525 1.0\n",
      "526 1.0\n",
      "527 1.0\n",
      "528 0.9999999999999998\n",
      "529 0.9999999999999998\n",
      "530 0.9999999999999998\n",
      "531 0.9999999999999998\n",
      "532 0.9999999999999998\n",
      "533 0.9999999999999998\n",
      "534 0.9999999999999998\n",
      "535 0.9999999999999998\n",
      "536 0.9999999999999998\n",
      "537 0.9999999999999998\n",
      "538 0.9999999999999998\n",
      "539 0.9999999999999998\n",
      "540 0.9999999999999998\n",
      "541 0.9999999999999998\n",
      "542 0.9999999999999998\n",
      "543 0.9999999999999998\n",
      "544 0.9999999999999998\n",
      "545 0.9999999999999998\n",
      "546 0.9999999999999998\n",
      "547 0.9999999999999998\n",
      "548 0.9999999999999998\n",
      "549 0.9999999999999998\n",
      "550 0.9999999999999998\n",
      "551 0.9999999999999998\n",
      "552 0.9999999999999998\n",
      "553 0.9999999999999998\n",
      "554 0.9999999999999998\n",
      "555 0.9999999999999998\n",
      "556 0.9999999999999998\n",
      "557 0.9999999999999998\n",
      "558 0.9999999999999998\n",
      "559 0.9999999999999998\n",
      "560 0.9999999999999998\n",
      "561 0.9999999999999998\n",
      "562 0.9999999999999998\n",
      "563 0.9999999999999998\n",
      "564 0.9999999999999998\n",
      "565 0.9999999999999998\n",
      "566 0.9999999999999998\n",
      "567 0.9999999999999998\n",
      "568 0.9999999999999998\n",
      "569 0.9999999999999998\n",
      "570 0.9999999999999998\n",
      "571 0.9999999999999998\n",
      "572 0.9999999999999998\n",
      "573 0.9999999999999998\n",
      "574 0.9999999999999998\n",
      "575 0.9999999999999998\n",
      "576 0.9999999999999998\n",
      "577 0.9999999999999998\n",
      "578 0.9999999999999998\n",
      "579 0.9999999999999998\n",
      "580 0.9999999999999998\n",
      "581 0.9999999999999998\n",
      "582 0.9999999999999998\n",
      "583 0.9999999999999998\n",
      "584 0.9999999999999998\n",
      "585 0.9999999999999998\n",
      "586 0.9999999999999998\n",
      "587 0.9999999999999998\n",
      "588 0.9999999999999998\n",
      "589 0.9999999999999998\n",
      "590 0.9999999999999998\n",
      "591 0.9999999999999998\n",
      "592 0.9999999999999998\n",
      "593 0.9999999999999998\n",
      "594 0.9999999999999998\n",
      "595 0.9999999999999998\n",
      "596 0.9999999999999998\n",
      "597 0.9999999999999998\n",
      "598 0.9999999999999998\n",
      "599 0.9999999999999998\n",
      "600 0.9999999999999998\n",
      "601 0.9999999999999998\n",
      "602 0.9999999999999998\n",
      "603 0.9999999999999998\n",
      "604 0.9999999999999998\n",
      "605 0.9999999999999998\n",
      "606 0.9999999999999998\n",
      "607 0.9999999999999998\n",
      "608 1.0\n",
      "609 1.0\n",
      "610 1.0\n",
      "611 1.0\n",
      "612 1.0\n",
      "613 1.0\n",
      "614 1.0\n",
      "615 1.0\n",
      "616 1.0\n",
      "617 1.0\n",
      "618 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2f588d69b578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ms_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0ms_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mX_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(X_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# code goes here\n",
    "classes = {}\n",
    "# classes[0] = X[np.where(y==0)]\n",
    "for i in range(8):\n",
    "    classes[i] = X[np.where(y==i)]\n",
    "\n",
    "cov = np.cov(classes[7].T) #check \n",
    "eigvals, eigvectors = np.linalg.eig(cov) \n",
    "full = np.sum(np.real(eigvals[:1024]))\n",
    "for i in range(classes[4].shape[1]):\n",
    "    s_vals = eigvals[:i]\n",
    "    s_vecs = eigvectors[:, :i]\n",
    "    X_k = np.dot(s_vecs.T, X.T).T\n",
    "    print(i, np.sum(np.real(s_vals))/full) \n",
    "# print(X_k)\n",
    "#class0 - 35 - Madhuri - Complex Facial Features. \n",
    "#class1 - 31\n",
    "#class2 - 33\n",
    "#class3 - 30\n",
    "#class4 - 31\n",
    "#class5 - 27 - Katrina Kaif - Simple face. Easily Representable with fewer eigen faces \n",
    "#class6 - 32\n",
    "#class7 - 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1024)\n",
      "(42, 1024)\n",
      "(79, 1024)\n",
      "(101, 1024)\n",
      "(100, 1024)\n",
      "(100, 1024)\n",
      "(100, 1024)\n",
      "(100, 1024)\n"
     ]
    }
   ],
   "source": [
    "classes_1 = {}\n",
    "for i in range(8):\n",
    "    classes_1[i] =(X_1[np.where(y_1==i)])\n",
    "    print(classes_1[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.2841987782367518\n",
      "2 0.3583000581742886\n",
      "3 0.4108251086908587\n",
      "4 0.44492301630517705\n",
      "5 0.4745210997711388\n",
      "6 0.49553730544040087\n",
      "7 0.5153457340631538\n",
      "8 0.5341582447823411\n",
      "9 0.5515331473581702\n",
      "10 0.568339794897892\n",
      "11 0.5839555412725903\n",
      "12 0.5974496874568392\n",
      "13 0.6102355795264814\n",
      "14 0.6227066019258556\n",
      "15 0.6344587406238806\n",
      "16 0.6458758760838924\n",
      "17 0.6566981441542649\n",
      "18 0.6670314856813733\n",
      "19 0.6769726578530334\n",
      "20 0.686503527134674\n",
      "21 0.6958202192156822\n",
      "22 0.7049057585733014\n",
      "23 0.7137693306931896\n",
      "24 0.7223018854915338\n",
      "25 0.7303993289203257\n",
      "26 0.7383853846065828\n",
      "27 0.7458666360058094\n",
      "28 0.753393558935698\n",
      "29 0.7606201840107225\n",
      "30 0.767676980595488\n",
      "31 0.7744784121589701\n",
      "32 0.7811441937851431\n",
      "33 0.7876919491285793\n",
      "34 0.7941251462033071\n",
      "35 0.8003906324674748\n",
      "36 0.8065289117330545\n",
      "37 0.8123284141075607\n",
      "38 0.8180497633898489\n",
      "39 0.8235925358792167\n",
      "40 0.8290695687940492\n",
      "41 0.8343649900129846\n",
      "42 0.8394817686030942\n",
      "43 0.8443725316276618\n",
      "44 0.8493396584284362\n",
      "45 0.8543757780660275\n",
      "46 0.8591626558701625\n",
      "47 0.8638247379436217\n",
      "48 0.8683708373519734\n",
      "49 0.8728362886853088\n",
      "50 0.8771230192416986\n",
      "51 0.8813550930239301\n",
      "52 0.8855185412352001\n",
      "53 0.8896176697264957\n",
      "54 0.8935548969628159\n",
      "55 0.8974306631743663\n",
      "56 0.901214769475413\n",
      "57 0.9049861262061435\n",
      "58 0.9085515814667988\n",
      "59 0.9120684401857467\n",
      "60 0.9155477389702148\n",
      "61 0.918962245329045\n",
      "62 0.9222861724616215\n",
      "63 0.9254858374761725\n",
      "64 0.9286448355481841\n",
      "65 0.9317622868430272\n",
      "66 0.9348603331746212\n",
      "67 0.9379319478726278\n",
      "68 0.9408919757009095\n",
      "69 0.943717618527429\n",
      "70 0.9466051139871527\n",
      "71 0.9494652258962303\n",
      "72 0.952183365605149\n",
      "73 0.9548716768435057\n",
      "74 0.9574217415668759\n",
      "75 0.9599288992087954\n",
      "76 0.9623894990484264\n",
      "77 0.9648125072108519\n",
      "78 0.9672147864413004\n",
      "79 0.9694762587146084\n",
      "80 0.9716801534331916\n",
      "81 0.9737807828558616\n",
      "82 0.9758243652044258\n",
      "83 0.9777918015016853\n",
      "84 0.9791182670646985\n",
      "85 0.980265646449338\n",
      "86 0.9822623071052247\n",
      "87 0.9837378712758909\n",
      "88 0.9854883730350769\n",
      "89 0.9871030266841245\n",
      "90 0.9887603092115168\n",
      "91 0.9905844397341695\n",
      "92 0.992444555011293\n",
      "93 0.9939412262995685\n",
      "94 0.9953729008107093\n",
      "95 0.997241483165183\n",
      "96 0.9982836691939532\n",
      "97 0.9991790256497773\n",
      "98 0.9998537723103968\n",
      "99 0.9999999999999998\n",
      "100 0.9999999999999998\n",
      "101 0.9999999999999998\n",
      "102 0.9999999999999998\n",
      "103 0.9999999999999998\n",
      "104 0.9999999999999998\n",
      "105 0.9999999999999998\n",
      "106 0.9999999999999998\n",
      "107 0.9999999999999998\n",
      "108 0.9999999999999998\n",
      "109 0.9999999999999998\n",
      "110 0.9999999999999998\n",
      "111 0.9999999999999998\n",
      "112 1.0\n",
      "113 1.0\n",
      "114 1.0\n",
      "115 1.0\n",
      "116 1.0\n",
      "117 1.0\n",
      "118 1.0\n",
      "119 1.0\n",
      "120 1.0\n",
      "121 1.0\n",
      "122 1.0\n",
      "123 1.0\n",
      "124 1.0\n",
      "125 1.0\n",
      "126 1.0\n",
      "127 1.0\n",
      "128 1.0\n",
      "129 1.0\n",
      "130 1.0\n",
      "131 0.9999999999999998\n",
      "132 1.0\n",
      "133 1.0\n",
      "134 1.0\n",
      "135 1.0\n",
      "136 1.0\n",
      "137 1.0\n",
      "138 0.9999999999999998\n",
      "139 1.0\n",
      "140 1.0\n",
      "141 1.0\n",
      "142 1.0\n",
      "143 1.0\n",
      "144 1.0\n",
      "145 1.0\n",
      "146 1.0\n",
      "147 1.0\n",
      "148 1.0\n",
      "149 1.0\n",
      "150 1.0\n",
      "151 1.0\n",
      "152 1.0\n",
      "153 1.0\n",
      "154 1.0\n",
      "155 1.0\n",
      "156 1.0\n",
      "157 1.0\n",
      "158 1.0\n",
      "159 1.0\n",
      "160 1.0\n",
      "161 1.0\n",
      "162 1.0\n",
      "163 1.0\n",
      "164 1.0\n",
      "165 1.0\n",
      "166 1.0\n",
      "167 1.0\n",
      "168 1.0\n",
      "169 1.0\n",
      "170 1.0\n",
      "171 1.0\n",
      "172 1.0\n",
      "173 1.0\n",
      "174 1.0\n",
      "175 1.0\n",
      "176 0.9999999999999998\n",
      "177 0.9999999999999998\n",
      "178 0.9999999999999998\n",
      "179 0.9999999999999998\n",
      "180 0.9999999999999998\n",
      "181 0.9999999999999998\n",
      "182 0.9999999999999998\n",
      "183 0.9999999999999998\n",
      "184 0.9999999999999998\n",
      "185 0.9999999999999998\n",
      "186 0.9999999999999998\n",
      "187 0.9999999999999998\n",
      "188 0.9999999999999998\n",
      "189 0.9999999999999998\n",
      "190 0.9999999999999998\n",
      "191 0.9999999999999998\n",
      "192 0.9999999999999998\n",
      "193 0.9999999999999998\n",
      "194 0.9999999999999998\n",
      "195 0.9999999999999998\n",
      "196 0.9999999999999998\n",
      "197 0.9999999999999998\n",
      "198 0.9999999999999998\n",
      "199 0.9999999999999998\n",
      "200 0.9999999999999998\n",
      "201 0.9999999999999998\n",
      "202 0.9999999999999998\n",
      "203 0.9999999999999998\n",
      "204 0.9999999999999998\n",
      "205 0.9999999999999998\n",
      "206 0.9999999999999998\n",
      "207 0.9999999999999998\n",
      "208 0.9999999999999998\n",
      "209 0.9999999999999998\n",
      "210 0.9999999999999998\n",
      "211 0.9999999999999998\n",
      "212 0.9999999999999998\n",
      "213 0.9999999999999998\n",
      "214 0.9999999999999998\n",
      "215 0.9999999999999998\n",
      "216 0.9999999999999998\n",
      "217 0.9999999999999998\n",
      "218 0.9999999999999998\n",
      "219 0.9999999999999998\n",
      "220 0.9999999999999998\n",
      "221 0.9999999999999998\n",
      "222 0.9999999999999998\n",
      "223 0.9999999999999998\n",
      "224 1.0\n",
      "225 1.0\n",
      "226 1.0\n",
      "227 1.0\n",
      "228 1.0\n",
      "229 1.0\n",
      "230 1.0\n",
      "231 1.0\n",
      "232 1.0\n",
      "233 1.0\n",
      "234 1.0\n",
      "235 1.0\n",
      "236 1.0\n",
      "237 1.0\n",
      "238 1.0\n",
      "239 1.0\n",
      "240 1.0\n",
      "241 1.0\n",
      "242 1.0\n",
      "243 1.0\n",
      "244 1.0\n",
      "245 1.0\n",
      "246 1.0\n",
      "247 1.0\n",
      "248 1.0\n",
      "249 1.0\n",
      "250 1.0\n",
      "251 1.0\n",
      "252 1.0\n",
      "253 1.0\n",
      "254 1.0\n",
      "255 1.0\n",
      "256 1.0\n",
      "257 1.0\n",
      "258 1.0\n",
      "259 1.0\n",
      "260 1.0\n",
      "261 1.0\n",
      "262 1.0\n",
      "263 1.0\n",
      "264 1.0\n",
      "265 1.0\n",
      "266 1.0\n",
      "267 1.0\n",
      "268 1.0\n",
      "269 1.0\n",
      "270 1.0\n",
      "271 1.0\n",
      "272 1.0\n",
      "273 1.0\n",
      "274 1.0\n",
      "275 1.0\n",
      "276 1.0\n",
      "277 1.0\n",
      "278 1.0\n",
      "279 1.0\n",
      "280 1.0\n",
      "281 1.0\n",
      "282 1.0\n",
      "283 1.0\n",
      "284 1.0\n",
      "285 1.0\n",
      "286 1.0\n",
      "287 1.0\n",
      "288 1.0\n",
      "289 1.0\n",
      "290 1.0\n",
      "291 1.0\n",
      "292 1.0\n",
      "293 1.0\n",
      "294 1.0\n",
      "295 1.0\n",
      "296 1.0\n",
      "297 1.0\n",
      "298 1.0\n",
      "299 1.0\n",
      "300 1.0\n",
      "301 1.0\n",
      "302 1.0\n",
      "303 1.0\n",
      "304 1.0\n",
      "305 1.0\n",
      "306 1.0\n",
      "307 1.0\n",
      "308 1.0\n",
      "309 1.0\n",
      "310 1.0\n",
      "311 1.0\n",
      "312 1.0\n",
      "313 1.0\n",
      "314 1.0\n",
      "315 1.0\n",
      "316 1.0\n",
      "317 1.0\n",
      "318 1.0\n",
      "319 1.0\n",
      "320 1.0\n",
      "321 1.0\n",
      "322 1.0\n",
      "323 1.0\n",
      "324 1.0\n",
      "325 1.0\n",
      "326 1.0\n",
      "327 1.0\n",
      "328 1.0\n",
      "329 1.0\n",
      "330 1.0\n",
      "331 1.0\n",
      "332 1.0\n",
      "333 1.0\n",
      "334 1.0\n",
      "335 1.0\n",
      "336 1.0\n",
      "337 1.0\n",
      "338 1.0\n",
      "339 1.0\n",
      "340 1.0\n",
      "341 1.0\n",
      "342 1.0\n",
      "343 1.0\n",
      "344 1.0\n",
      "345 1.0\n",
      "346 1.0\n",
      "347 1.0\n",
      "348 1.0\n",
      "349 1.0\n",
      "350 1.0\n",
      "351 1.0\n",
      "352 0.9999999999999998\n",
      "353 0.9999999999999998\n",
      "354 0.9999999999999998\n",
      "355 0.9999999999999998\n",
      "356 0.9999999999999998\n",
      "357 0.9999999999999998\n",
      "358 0.9999999999999998\n",
      "359 0.9999999999999998\n",
      "360 0.9999999999999998\n",
      "361 0.9999999999999998\n",
      "362 0.9999999999999998\n",
      "363 0.9999999999999998\n",
      "364 0.9999999999999998\n",
      "365 0.9999999999999998\n",
      "366 0.9999999999999998\n",
      "367 0.9999999999999998\n",
      "368 0.9999999999999998\n",
      "369 0.9999999999999998\n",
      "370 0.9999999999999998\n",
      "371 0.9999999999999998\n",
      "372 0.9999999999999998\n",
      "373 0.9999999999999998\n",
      "374 0.9999999999999998\n",
      "375 0.9999999999999998\n",
      "376 0.9999999999999998\n",
      "377 0.9999999999999998\n",
      "378 0.9999999999999998\n",
      "379 0.9999999999999998\n",
      "380 0.9999999999999998\n",
      "381 0.9999999999999998\n",
      "382 0.9999999999999998\n",
      "383 0.9999999999999998\n",
      "384 0.9999999999999998\n",
      "385 0.9999999999999998\n",
      "386 0.9999999999999998\n",
      "387 0.9999999999999998\n",
      "388 0.9999999999999998\n",
      "389 0.9999999999999998\n",
      "390 0.9999999999999998\n",
      "391 0.9999999999999998\n",
      "392 0.9999999999999998\n",
      "393 0.9999999999999998\n",
      "394 0.9999999999999998\n",
      "395 0.9999999999999998\n",
      "396 0.9999999999999998\n",
      "397 0.9999999999999998\n",
      "398 0.9999999999999998\n",
      "399 0.9999999999999998\n",
      "400 0.9999999999999998\n",
      "401 0.9999999999999998\n",
      "402 0.9999999999999998\n",
      "403 0.9999999999999998\n",
      "404 0.9999999999999998\n",
      "405 0.9999999999999998\n",
      "406 0.9999999999999998\n",
      "407 0.9999999999999998\n",
      "408 0.9999999999999998\n",
      "409 0.9999999999999998\n",
      "410 0.9999999999999998\n",
      "411 0.9999999999999998\n",
      "412 0.9999999999999998\n",
      "413 0.9999999999999998\n",
      "414 0.9999999999999998\n",
      "415 0.9999999999999998\n",
      "416 0.9999999999999998\n",
      "417 0.9999999999999998\n",
      "418 0.9999999999999998\n",
      "419 0.9999999999999998\n",
      "420 0.9999999999999998\n",
      "421 0.9999999999999998\n",
      "422 0.9999999999999998\n",
      "423 0.9999999999999998\n",
      "424 0.9999999999999998\n",
      "425 0.9999999999999998\n",
      "426 0.9999999999999998\n",
      "427 0.9999999999999998\n",
      "428 0.9999999999999998\n",
      "429 0.9999999999999998\n",
      "430 0.9999999999999998\n",
      "431 0.9999999999999998\n",
      "432 0.9999999999999998\n",
      "433 0.9999999999999998\n",
      "434 0.9999999999999998\n",
      "435 0.9999999999999998\n",
      "436 0.9999999999999998\n",
      "437 0.9999999999999998\n",
      "438 0.9999999999999998\n",
      "439 0.9999999999999998\n",
      "440 0.9999999999999998\n",
      "441 0.9999999999999998\n",
      "442 0.9999999999999998\n",
      "443 0.9999999999999998\n",
      "444 0.9999999999999998\n",
      "445 0.9999999999999998\n",
      "446 0.9999999999999998\n",
      "447 0.9999999999999998\n",
      "448 1.0\n",
      "449 1.0\n",
      "450 1.0\n",
      "451 1.0\n",
      "452 1.0\n",
      "453 1.0\n",
      "454 1.0\n",
      "455 1.0\n",
      "456 1.0\n",
      "457 1.0\n",
      "458 1.0\n",
      "459 1.0\n",
      "460 1.0\n",
      "461 1.0\n",
      "462 1.0\n",
      "463 1.0\n",
      "464 1.0\n",
      "465 1.0\n",
      "466 1.0\n",
      "467 1.0\n",
      "468 1.0\n",
      "469 1.0\n",
      "470 1.0\n",
      "471 1.0\n",
      "472 1.0\n",
      "473 1.0\n",
      "474 1.0\n",
      "475 1.0\n",
      "476 1.0\n",
      "477 1.0\n",
      "478 1.0\n",
      "479 1.0\n",
      "480 1.0\n",
      "481 1.0\n",
      "482 1.0\n",
      "483 1.0\n",
      "484 1.0\n",
      "485 1.0\n",
      "486 1.0\n",
      "487 1.0\n",
      "488 1.0\n",
      "489 1.0\n",
      "490 1.0\n",
      "491 1.0\n",
      "492 1.0\n",
      "493 1.0\n",
      "494 1.0\n",
      "495 1.0\n",
      "496 1.0\n",
      "497 1.0\n",
      "498 1.0\n",
      "499 1.0\n",
      "500 1.0\n",
      "501 1.0\n",
      "502 1.0\n",
      "503 1.0\n",
      "504 1.0\n",
      "505 1.0\n",
      "506 1.0\n",
      "507 1.0\n",
      "508 1.0\n",
      "509 1.0\n",
      "510 1.0\n",
      "511 1.0\n",
      "512 1.0\n",
      "513 1.0\n",
      "514 1.0\n",
      "515 1.0\n",
      "516 1.0\n",
      "517 1.0\n",
      "518 1.0\n",
      "519 1.0\n",
      "520 1.0\n",
      "521 1.0\n",
      "522 1.0\n",
      "523 1.0\n",
      "524 1.0\n",
      "525 1.0\n",
      "526 1.0\n",
      "527 1.0\n",
      "528 1.0\n",
      "529 1.0\n",
      "530 1.0\n",
      "531 1.0\n",
      "532 1.0\n",
      "533 1.0\n",
      "534 1.0\n",
      "535 1.0\n",
      "536 1.0\n",
      "537 1.0\n",
      "538 1.0\n",
      "539 1.0\n",
      "540 1.0\n",
      "541 1.0\n",
      "542 1.0\n",
      "543 1.0\n",
      "544 1.0\n",
      "545 1.0\n",
      "546 1.0\n",
      "547 1.0\n",
      "548 1.0\n",
      "549 1.0\n",
      "550 1.0\n",
      "551 1.0\n",
      "552 1.0\n",
      "553 1.0\n",
      "554 1.0\n",
      "555 1.0\n",
      "556 1.0\n",
      "557 1.0\n",
      "558 1.0\n",
      "559 1.0\n",
      "560 1.0\n",
      "561 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 1.0\n",
      "563 1.0\n",
      "564 1.0\n",
      "565 1.0\n",
      "566 1.0\n",
      "567 1.0\n",
      "568 1.0\n",
      "569 1.0\n",
      "570 1.0\n",
      "571 1.0\n",
      "572 1.0\n",
      "573 1.0\n",
      "574 1.0\n",
      "575 1.0\n",
      "576 1.0\n",
      "577 1.0\n",
      "578 1.0\n",
      "579 1.0\n",
      "580 1.0\n",
      "581 1.0\n",
      "582 1.0\n",
      "583 1.0\n",
      "584 1.0\n",
      "585 1.0\n",
      "586 1.0\n",
      "587 1.0\n",
      "588 1.0\n",
      "589 1.0\n",
      "590 1.0\n",
      "591 1.0\n",
      "592 1.0\n",
      "593 1.0\n",
      "594 1.0\n",
      "595 1.0\n",
      "596 1.0\n",
      "597 1.0\n",
      "598 1.0\n",
      "599 1.0\n",
      "600 1.0\n",
      "601 1.0\n",
      "602 1.0\n",
      "603 1.0\n",
      "604 1.0\n",
      "605 1.0\n",
      "606 1.0\n",
      "607 1.0\n",
      "608 1.0\n",
      "609 1.0\n",
      "610 1.0\n",
      "611 1.0\n",
      "612 1.0\n",
      "613 1.0\n",
      "614 1.0\n",
      "615 1.0\n",
      "616 1.0\n",
      "617 1.0\n",
      "618 1.0\n",
      "619 1.0\n",
      "620 1.0\n",
      "621 1.0\n",
      "622 1.0\n",
      "623 1.0\n",
      "624 1.0\n",
      "625 1.0\n",
      "626 1.0\n",
      "627 1.0\n",
      "628 1.0\n",
      "629 1.0\n",
      "630 1.0\n",
      "631 1.0\n",
      "632 1.0\n",
      "633 1.0\n",
      "634 1.0\n",
      "635 1.0\n",
      "636 1.0\n",
      "637 1.0\n",
      "638 1.0\n",
      "639 1.0\n",
      "640 1.0\n",
      "641 1.0\n",
      "642 1.0\n",
      "643 1.0\n",
      "644 1.0\n",
      "645 1.0\n",
      "646 1.0\n",
      "647 1.0\n",
      "648 1.0\n",
      "649 1.0\n",
      "650 1.0\n",
      "651 1.0\n",
      "652 1.0\n",
      "653 1.0\n",
      "654 1.0\n",
      "655 1.0\n",
      "656 1.0\n",
      "657 1.0\n",
      "658 1.0\n",
      "659 1.0\n",
      "660 1.0\n",
      "661 1.0\n",
      "662 1.0\n",
      "663 1.0\n",
      "664 1.0\n",
      "665 1.0\n",
      "666 1.0\n",
      "667 1.0\n",
      "668 1.0\n",
      "669 1.0\n",
      "670 1.0\n",
      "671 1.0\n",
      "672 1.0\n",
      "673 1.0\n",
      "674 1.0\n",
      "675 1.0\n",
      "676 1.0\n",
      "677 1.0\n",
      "678 1.0\n",
      "679 1.0\n",
      "680 1.0\n",
      "681 1.0\n",
      "682 1.0\n",
      "683 1.0\n",
      "684 1.0\n",
      "685 1.0\n",
      "686 1.0\n",
      "687 1.0\n",
      "688 1.0\n",
      "689 1.0\n",
      "690 1.0\n",
      "691 1.0\n",
      "692 1.0\n",
      "693 1.0\n",
      "694 1.0\n",
      "695 1.0\n",
      "696 1.0\n",
      "697 1.0\n",
      "698 1.0\n",
      "699 1.0\n",
      "700 1.0\n",
      "701 1.0\n",
      "702 1.0\n",
      "703 1.0\n",
      "704 0.9999999999999998\n",
      "705 0.9999999999999998\n",
      "706 0.9999999999999998\n",
      "707 0.9999999999999998\n",
      "708 0.9999999999999998\n",
      "709 0.9999999999999998\n",
      "710 0.9999999999999998\n",
      "711 0.9999999999999998\n",
      "712 0.9999999999999998\n",
      "713 0.9999999999999998\n",
      "714 0.9999999999999998\n",
      "715 0.9999999999999998\n",
      "716 0.9999999999999998\n",
      "717 0.9999999999999998\n",
      "718 0.9999999999999998\n",
      "719 0.9999999999999998\n",
      "720 0.9999999999999998\n",
      "721 0.9999999999999998\n",
      "722 0.9999999999999998\n",
      "723 0.9999999999999998\n",
      "724 0.9999999999999998\n",
      "725 0.9999999999999998\n",
      "726 0.9999999999999998\n",
      "727 0.9999999999999998\n",
      "728 0.9999999999999998\n",
      "729 0.9999999999999998\n",
      "730 0.9999999999999998\n",
      "731 0.9999999999999998\n",
      "732 0.9999999999999998\n",
      "733 0.9999999999999998\n",
      "734 0.9999999999999998\n",
      "735 0.9999999999999998\n",
      "736 0.9999999999999998\n",
      "737 0.9999999999999998\n",
      "738 0.9999999999999998\n",
      "739 0.9999999999999998\n",
      "740 0.9999999999999998\n",
      "741 0.9999999999999998\n",
      "742 0.9999999999999998\n",
      "743 0.9999999999999998\n",
      "744 0.9999999999999998\n",
      "745 0.9999999999999998\n",
      "746 0.9999999999999998\n",
      "747 0.9999999999999998\n",
      "748 0.9999999999999998\n",
      "749 0.9999999999999998\n",
      "750 0.9999999999999998\n",
      "751 0.9999999999999998\n",
      "752 0.9999999999999998\n",
      "753 0.9999999999999998\n",
      "754 0.9999999999999998\n",
      "755 0.9999999999999998\n",
      "756 0.9999999999999998\n",
      "757 0.9999999999999998\n",
      "758 0.9999999999999998\n",
      "759 0.9999999999999998\n",
      "760 0.9999999999999998\n",
      "761 0.9999999999999998\n",
      "762 0.9999999999999998\n",
      "763 0.9999999999999998\n",
      "764 0.9999999999999998\n",
      "765 0.9999999999999998\n",
      "766 0.9999999999999998\n",
      "767 0.9999999999999998\n",
      "768 0.9999999999999998\n",
      "769 0.9999999999999998\n",
      "770 0.9999999999999998\n",
      "771 0.9999999999999998\n",
      "772 0.9999999999999998\n",
      "773 0.9999999999999998\n",
      "774 0.9999999999999998\n",
      "775 0.9999999999999998\n",
      "776 0.9999999999999998\n",
      "777 0.9999999999999998\n",
      "778 0.9999999999999998\n",
      "779 0.9999999999999998\n",
      "780 0.9999999999999998\n",
      "781 0.9999999999999998\n",
      "782 0.9999999999999998\n",
      "783 0.9999999999999998\n",
      "784 0.9999999999999998\n",
      "785 0.9999999999999998\n",
      "786 0.9999999999999998\n",
      "787 0.9999999999999998\n",
      "788 0.9999999999999998\n",
      "789 0.9999999999999998\n",
      "790 0.9999999999999998\n",
      "791 0.9999999999999998\n",
      "792 0.9999999999999998\n",
      "793 0.9999999999999998\n",
      "794 0.9999999999999998\n",
      "795 0.9999999999999998\n",
      "796 0.9999999999999998\n",
      "797 0.9999999999999998\n",
      "798 0.9999999999999998\n",
      "799 0.9999999999999998\n",
      "800 0.9999999999999998\n",
      "801 0.9999999999999998\n",
      "802 0.9999999999999998\n",
      "803 0.9999999999999998\n",
      "804 0.9999999999999998\n",
      "805 0.9999999999999998\n",
      "806 0.9999999999999998\n",
      "807 0.9999999999999998\n",
      "808 0.9999999999999998\n",
      "809 0.9999999999999998\n",
      "810 0.9999999999999998\n",
      "811 0.9999999999999998\n",
      "812 0.9999999999999998\n",
      "813 0.9999999999999998\n",
      "814 0.9999999999999998\n",
      "815 0.9999999999999998\n",
      "816 0.9999999999999998\n",
      "817 0.9999999999999998\n",
      "818 0.9999999999999998\n",
      "819 0.9999999999999998\n",
      "820 0.9999999999999998\n",
      "821 0.9999999999999998\n",
      "822 0.9999999999999998\n",
      "823 0.9999999999999998\n",
      "824 0.9999999999999998\n",
      "825 0.9999999999999998\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-ba92bc114c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms_vals_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvals_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0ms_vecs_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvectors_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_k_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vecs_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vals_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfull_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(np.shape(X_1[np.where(y_1==3)]))\n",
    "cov_1 = np.cov(classes_1[7].T) #check \n",
    "eigvals_1, eigvectors_1 = np.linalg.eig(cov_1) \n",
    "full_1 = np.sum(np.real(eigvals_1))\n",
    "for i in range(classes_1[1].shape[1]):\n",
    "    s_vals_1 = eigvals_1[:i]\n",
    "    s_vecs_1 = eigvectors_1[:, :i]\n",
    "    X_k_1 = np.dot(s_vecs_1.T, X_1.T).T\n",
    "    print(i, np.sum(np.real(s_vals_1))/full_1) \n",
    "    \n",
    "# class0 - 33\n",
    "# class1 - 33\n",
    "# class2 - 49 \n",
    "# class3 - 65\n",
    "# class4 - 71\n",
    "# class5 - 79\n",
    "# class6 - 77\n",
    "# class7 - 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_2 = {}\n",
    "for i in range(8):\n",
    "    classes_2[i] =(X_2[np.where(y_2==i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.4417848782067818\n",
      "2 0.7170597674161261\n",
      "3 0.7999041678911463\n",
      "4 0.8561323982036534\n",
      "5 0.9012622738368331\n",
      "6 0.929229174709668\n",
      "7 0.9527020088213085\n",
      "8 0.9730573242405345\n",
      "9 0.9881980713515808\n",
      "10 1.0000000000000002\n",
      "11 1.0000000000000002\n",
      "12 1.0000000000000002\n",
      "13 1.0000000000000002\n",
      "14 1.0000000000000002\n",
      "15 1.0000000000000002\n",
      "16 1.0000000000000004\n",
      "17 1.0000000000000004\n",
      "18 1.0000000000000004\n",
      "19 1.0000000000000004\n",
      "20 1.0000000000000004\n",
      "21 1.0000000000000004\n",
      "22 1.0000000000000004\n",
      "23 1.0000000000000004\n",
      "24 1.0000000000000004\n",
      "25 1.0000000000000004\n",
      "26 1.0000000000000004\n",
      "27 1.0000000000000004\n",
      "28 1.0000000000000004\n",
      "29 1.0000000000000004\n",
      "30 1.0000000000000004\n",
      "31 1.0000000000000004\n",
      "32 1.0000000000000004\n",
      "33 1.0000000000000004\n",
      "34 1.0000000000000004\n",
      "35 1.0000000000000004\n",
      "36 1.0000000000000004\n",
      "37 1.0000000000000004\n",
      "38 1.0000000000000004\n",
      "39 1.0000000000000004\n",
      "40 1.0000000000000004\n",
      "41 1.0000000000000004\n",
      "42 1.0000000000000004\n",
      "43 1.0000000000000004\n",
      "44 1.0000000000000004\n",
      "45 1.0000000000000004\n",
      "46 1.0000000000000004\n",
      "47 1.0000000000000004\n",
      "48 1.0000000000000004\n",
      "49 1.0000000000000004\n",
      "50 1.0000000000000004\n",
      "51 1.0000000000000004\n",
      "52 1.0000000000000004\n",
      "53 1.0000000000000004\n",
      "54 1.0000000000000004\n",
      "55 1.0000000000000004\n",
      "56 1.0000000000000004\n",
      "57 1.0000000000000004\n",
      "58 1.0000000000000004\n",
      "59 1.0000000000000004\n",
      "60 1.0000000000000004\n",
      "61 1.0000000000000004\n",
      "62 1.0000000000000004\n",
      "63 1.0000000000000004\n",
      "64 1.0000000000000004\n",
      "65 1.0000000000000004\n",
      "66 1.0000000000000004\n",
      "67 1.0000000000000004\n",
      "68 1.0000000000000004\n",
      "69 1.0000000000000004\n",
      "70 1.0000000000000004\n",
      "71 1.0000000000000004\n",
      "72 1.0000000000000004\n",
      "73 1.0000000000000004\n",
      "74 1.0000000000000004\n",
      "75 1.0000000000000004\n",
      "76 1.0000000000000004\n",
      "77 1.0000000000000004\n",
      "78 1.0000000000000004\n",
      "79 1.0000000000000004\n",
      "80 1.0000000000000004\n",
      "81 1.0000000000000004\n",
      "82 1.0000000000000004\n",
      "83 1.0000000000000004\n",
      "84 1.0000000000000004\n",
      "85 1.0000000000000004\n",
      "86 1.0000000000000004\n",
      "87 1.0000000000000004\n",
      "88 1.0000000000000004\n",
      "89 1.0000000000000004\n",
      "90 1.0000000000000004\n",
      "91 1.0000000000000004\n",
      "92 1.0000000000000004\n",
      "93 1.0000000000000004\n",
      "94 1.0000000000000004\n",
      "95 1.0000000000000004\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n",
      "100 1.0\n",
      "101 1.0\n",
      "102 1.0\n",
      "103 1.0\n",
      "104 1.0\n",
      "105 1.0\n",
      "106 1.0\n",
      "107 1.0\n",
      "108 1.0\n",
      "109 1.0\n",
      "110 1.0\n",
      "111 1.0\n",
      "112 1.0\n",
      "113 1.0\n",
      "114 1.0\n",
      "115 1.0\n",
      "116 1.0\n",
      "117 1.0\n",
      "118 1.0\n",
      "119 1.0\n",
      "120 1.0\n",
      "121 1.0\n",
      "122 1.0\n",
      "123 1.0\n",
      "124 1.0\n",
      "125 1.0\n",
      "126 1.0\n",
      "127 1.0\n",
      "128 1.0\n",
      "129 1.0000000000000004\n",
      "130 1.0000000000000004\n",
      "131 1.0000000000000004\n",
      "132 1.0000000000000002\n",
      "133 1.0000000000000002\n",
      "134 1.0000000000000002\n",
      "135 1.0000000000000002\n",
      "136 1.0000000000000002\n",
      "137 1.0000000000000002\n",
      "138 1.0000000000000002\n",
      "139 1.0000000000000002\n",
      "140 1.0000000000000002\n",
      "141 1.0000000000000002\n",
      "142 1.0000000000000002\n",
      "143 1.0000000000000002\n",
      "144 1.0000000000000002\n",
      "145 1.0000000000000002\n",
      "146 1.0000000000000002\n",
      "147 1.0000000000000002\n",
      "148 1.0000000000000002\n",
      "149 1.0000000000000002\n",
      "150 1.0000000000000002\n",
      "151 1.0000000000000002\n",
      "152 1.0000000000000002\n",
      "153 1.0000000000000002\n",
      "154 1.0000000000000002\n",
      "155 1.0000000000000002\n",
      "156 1.0000000000000002\n",
      "157 1.0000000000000002\n",
      "158 1.0000000000000002\n",
      "159 1.0000000000000002\n",
      "160 1.0000000000000002\n",
      "161 1.0000000000000002\n",
      "162 1.0000000000000002\n",
      "163 1.0000000000000002\n",
      "164 1.0000000000000002\n",
      "165 1.0000000000000002\n",
      "166 1.0000000000000004\n",
      "167 1.0000000000000004\n",
      "168 1.0000000000000004\n",
      "169 1.0000000000000004\n",
      "170 1.0000000000000004\n",
      "171 1.0000000000000004\n",
      "172 1.0000000000000004\n",
      "173 1.0000000000000004\n",
      "174 1.0000000000000004\n",
      "175 1.0000000000000004\n",
      "176 1.0000000000000004\n",
      "177 1.0000000000000004\n",
      "178 1.0000000000000004\n",
      "179 1.0000000000000004\n",
      "180 1.0000000000000004\n",
      "181 1.0000000000000004\n",
      "182 1.0000000000000004\n",
      "183 1.0000000000000004\n",
      "184 1.0000000000000004\n",
      "185 1.0000000000000004\n",
      "186 1.0000000000000004\n",
      "187 1.0000000000000004\n",
      "188 1.0000000000000004\n",
      "189 1.0000000000000004\n",
      "190 1.0000000000000004\n",
      "191 1.0000000000000004\n",
      "192 1.0\n",
      "193 1.0\n",
      "194 1.0\n",
      "195 1.0\n",
      "196 1.0\n",
      "197 1.0\n",
      "198 1.0\n",
      "199 1.0\n",
      "200 1.0\n",
      "201 1.0\n",
      "202 1.0\n",
      "203 1.0\n",
      "204 1.0\n",
      "205 1.0\n",
      "206 1.0\n",
      "207 1.0\n",
      "208 1.0\n",
      "209 1.0\n",
      "210 1.0\n",
      "211 1.0\n",
      "212 1.0\n",
      "213 1.0\n",
      "214 1.0\n",
      "215 1.0\n",
      "216 1.0\n",
      "217 1.0\n",
      "218 1.0\n",
      "219 1.0\n",
      "220 1.0\n",
      "221 1.0\n",
      "222 1.0\n",
      "223 1.0\n",
      "224 1.0\n",
      "225 1.0\n",
      "226 1.0\n",
      "227 1.0\n",
      "228 1.0\n",
      "229 1.0\n",
      "230 1.0\n",
      "231 1.0\n",
      "232 1.0\n",
      "233 1.0\n",
      "234 1.0\n",
      "235 1.0\n",
      "236 1.0\n",
      "237 1.0\n",
      "238 1.0\n",
      "239 1.0\n",
      "240 1.0\n",
      "241 1.0\n",
      "242 1.0\n",
      "243 1.0\n",
      "244 1.0\n",
      "245 1.0\n",
      "246 1.0\n",
      "247 1.0\n",
      "248 1.0\n",
      "249 1.0\n",
      "250 1.0\n",
      "251 1.0\n",
      "252 1.0\n",
      "253 1.0\n",
      "254 1.0\n",
      "255 1.0\n",
      "256 1.0\n",
      "257 1.0\n",
      "258 1.0\n",
      "259 1.0\n",
      "260 1.0\n",
      "261 1.0\n",
      "262 1.0\n",
      "263 1.0\n",
      "264 1.0\n",
      "265 1.0\n",
      "266 1.0\n",
      "267 1.0\n",
      "268 1.0\n",
      "269 1.0\n",
      "270 1.0\n",
      "271 1.0\n",
      "272 1.0000000000000002\n",
      "273 1.0000000000000002\n",
      "274 1.0000000000000002\n",
      "275 1.0000000000000002\n",
      "276 1.0000000000000002\n",
      "277 1.0000000000000002\n",
      "278 1.0000000000000002\n",
      "279 1.0000000000000002\n",
      "280 1.0000000000000002\n",
      "281 1.0000000000000002\n",
      "282 1.0000000000000002\n",
      "283 1.0000000000000002\n",
      "284 1.0000000000000002\n",
      "285 1.0000000000000002\n",
      "286 1.0000000000000002\n",
      "287 1.0000000000000002\n",
      "288 1.0000000000000002\n",
      "289 1.0000000000000002\n",
      "290 1.0000000000000002\n",
      "291 1.0000000000000002\n",
      "292 1.0000000000000002\n",
      "293 1.0000000000000002\n",
      "294 1.0000000000000002\n",
      "295 1.0000000000000002\n",
      "296 1.0000000000000002\n",
      "297 1.0000000000000002\n",
      "298 1.0000000000000002\n",
      "299 1.0000000000000002\n",
      "300 1.0000000000000002\n",
      "301 1.0000000000000002\n",
      "302 1.0000000000000002\n",
      "303 1.0000000000000002\n",
      "304 1.0000000000000002\n",
      "305 1.0000000000000002\n",
      "306 1.0000000000000002\n",
      "307 1.0000000000000002\n",
      "308 1.0000000000000002\n",
      "309 1.0000000000000002\n",
      "310 1.0000000000000002\n",
      "311 1.0000000000000002\n",
      "312 1.0000000000000002\n",
      "313 1.0000000000000002\n",
      "314 1.0000000000000002\n",
      "315 1.0000000000000002\n",
      "316 1.0000000000000002\n",
      "317 1.0000000000000002\n",
      "318 1.0000000000000002\n",
      "319 1.0000000000000002\n",
      "320 1.0000000000000002\n",
      "321 1.0000000000000002\n",
      "322 1.0000000000000002\n",
      "323 1.0000000000000002\n",
      "324 1.0000000000000002\n",
      "325 1.0000000000000002\n",
      "326 1.0000000000000002\n",
      "327 1.0000000000000002\n",
      "328 1.0000000000000002\n",
      "329 1.0000000000000002\n",
      "330 1.0000000000000002\n",
      "331 1.0000000000000002\n",
      "332 1.0000000000000002\n",
      "333 1.0000000000000002\n",
      "334 1.0000000000000002\n",
      "335 1.0000000000000002\n",
      "336 1.0000000000000004\n",
      "337 1.0000000000000004\n",
      "338 1.0000000000000004\n",
      "339 1.0000000000000004\n",
      "340 1.0000000000000004\n",
      "341 1.0000000000000004\n",
      "342 1.0000000000000004\n",
      "343 1.0000000000000004\n",
      "344 1.0000000000000004\n",
      "345 1.0000000000000004\n",
      "346 1.0000000000000004\n",
      "347 1.0000000000000004\n",
      "348 1.0000000000000004\n",
      "349 1.0000000000000004\n",
      "350 1.0000000000000004\n",
      "351 1.0000000000000004\n",
      "352 1.0000000000000004\n",
      "353 1.0000000000000004\n",
      "354 1.0000000000000004\n",
      "355 1.0000000000000004\n",
      "356 1.0000000000000004\n",
      "357 1.0000000000000004\n",
      "358 1.0000000000000004\n",
      "359 1.0000000000000004\n",
      "360 1.0000000000000004\n",
      "361 1.0000000000000004\n",
      "362 1.0000000000000004\n",
      "363 1.0000000000000004\n",
      "364 1.0000000000000004\n",
      "365 1.0000000000000004\n",
      "366 1.0000000000000004\n",
      "367 1.0000000000000004\n",
      "368 1.0000000000000004\n",
      "369 1.0000000000000004\n",
      "370 1.0000000000000004\n",
      "371 1.0000000000000004\n",
      "372 1.0000000000000004\n",
      "373 1.0000000000000004\n",
      "374 1.0000000000000004\n",
      "375 1.0000000000000004\n",
      "376 1.0000000000000004\n",
      "377 1.0000000000000004\n",
      "378 1.0000000000000004\n",
      "379 1.0000000000000004\n",
      "380 1.0000000000000004\n",
      "381 1.0000000000000004\n",
      "382 1.0000000000000004\n",
      "383 1.0000000000000004\n",
      "384 1.0\n",
      "385 1.0\n",
      "386 1.0\n",
      "387 1.0\n",
      "388 1.0\n",
      "389 1.0\n",
      "390 1.0\n",
      "391 1.0\n",
      "392 1.0\n",
      "393 1.0\n",
      "394 1.0\n",
      "395 1.0\n",
      "396 1.0\n",
      "397 1.0\n",
      "398 1.0\n",
      "399 1.0\n",
      "400 1.0\n",
      "401 1.0\n",
      "402 1.0\n",
      "403 1.0\n",
      "404 1.0\n",
      "405 1.0\n",
      "406 1.0\n",
      "407 1.0\n",
      "408 1.0\n",
      "409 1.0\n",
      "410 1.0\n",
      "411 1.0\n",
      "412 1.0\n",
      "413 1.0\n",
      "414 1.0\n",
      "415 1.0\n",
      "416 1.0\n",
      "417 1.0\n",
      "418 1.0\n",
      "419 1.0\n",
      "420 1.0\n",
      "421 1.0\n",
      "422 1.0\n",
      "423 1.0\n",
      "424 1.0\n",
      "425 1.0\n",
      "426 1.0\n",
      "427 1.0\n",
      "428 1.0\n",
      "429 1.0\n",
      "430 1.0\n",
      "431 1.0\n",
      "432 1.0\n",
      "433 1.0\n",
      "434 1.0\n",
      "435 1.0\n",
      "436 1.0\n",
      "437 1.0\n",
      "438 1.0\n",
      "439 1.0\n",
      "440 1.0\n",
      "441 1.0\n",
      "442 1.0\n",
      "443 1.0\n",
      "444 1.0\n",
      "445 1.0\n",
      "446 1.0\n",
      "447 1.0\n",
      "448 1.0\n",
      "449 1.0\n",
      "450 1.0\n",
      "451 1.0\n",
      "452 1.0\n",
      "453 1.0\n",
      "454 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-e12fb003b12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms_vals_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvals_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0ms_vecs_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvectors_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX_k_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vecs_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_vals_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfull_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cov_2 = np.cov(classes_2[0].T) #check \n",
    "eigvals_2, eigvectors_2 = np.linalg.eig(cov_2) \n",
    "full_2 = np.sum(np.real(eigvals_2))\n",
    "for i in range(classes_2[1].shape[1]):\n",
    "    s_vals_2 = eigvals_2[:i]\n",
    "    s_vecs_2 = eigvectors_2[:, :i]\n",
    "    X_k_2 = np.dot(s_vecs_2.T, X_2.T).T\n",
    "    print(i, np.sum(np.real(s_vals_2))/full_2) \n",
    "\n",
    "#class7 - 8\n",
    "#class6 - 7\n",
    "#class5 - 7 \n",
    "#class4 - 7 \n",
    "#class3 - 7 \n",
    "#class2 - 7\n",
    "#class1 - 7 \n",
    "#class0 - 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(a). Use any classifier(MLP, Logistic regression, SVM, Decision Trees) and find the classification accuracy. \n",
    "\n",
    "2(b) Which method works well? Do a comparitivestudy. \n",
    "\n",
    "In my opinion, out of the 6 combinations that I have tried, Resnet + LDA + MLP works best with all the datasets given. \n",
    "\n",
    "You already know the paper [Face Recognition Using  Kernel  Methods](!http://face-rec.org/algorithms/Kernel/nips01.pdf) .See  this  as  an  example for empirical analysis of different features/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "# MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "import sklearn as sk\n",
    "class Classifier():\n",
    "    def __init__(self, X_train):\n",
    "#         super.__init__()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(35, input_dim=X_train.shape[1], activation='relu'))# layer 1 neuron 1000\n",
    "        model.add(Dense(35, activation='relu'))# layer 2 neuron 1000\n",
    "        model.add(Dense(8, activation='sigmoid'))# output layer\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        predict = model.predict(X)\n",
    "        return prediction\n",
    "        \n",
    "    def confusion_matrix(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or classifier) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        confusion_matrix = sk.metrics.confusion_matrix(y, pred)\n",
    "        return confusion_matrix\n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train,epochs=100)\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict_classes(X_validate)\n",
    "        # Create a confusion matrix\n",
    "        confusion_matrix = self.confusion_matrix(y_pred, y_validate)\n",
    "        # Calculate Validation accuracy \n",
    "        # Calculate precision and recall \n",
    "        # Calculate F1-score \n",
    "        target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6',  'class 7']\n",
    "        classification_report = sk.metrics.classification_report(y_validate, y_pred, target_names=target_names)\n",
    "        return confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 481us/step - loss: 2.0813 - accuracy: 0.1094\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 2.0284 - accuracy: 0.1594\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.9865 - accuracy: 0.1969\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 1.9459 - accuracy: 0.2719\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 1.9030 - accuracy: 0.3375\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 1.8559 - accuracy: 0.4062\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.8030 - accuracy: 0.4875\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 1.7427 - accuracy: 0.5625\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 1.6748 - accuracy: 0.6187\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.5992 - accuracy: 0.6531\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.5126 - accuracy: 0.6969\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 1.4132 - accuracy: 0.7063\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 1.2984 - accuracy: 0.7594\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 1.1699 - accuracy: 0.7937\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 1.0369 - accuracy: 0.8094\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.9080 - accuracy: 0.8313\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 59us/step - loss: 0.7943 - accuracy: 0.8469\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.6928 - accuracy: 0.8562\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.6102 - accuracy: 0.8750\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.5379 - accuracy: 0.8875\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.4782 - accuracy: 0.8969\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 0.4238 - accuracy: 0.9219\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.3809 - accuracy: 0.9312\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.3361 - accuracy: 0.9406\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.2996 - accuracy: 0.9563\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.2694 - accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.2429 - accuracy: 0.9656\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.2185 - accuracy: 0.9719\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.1975 - accuracy: 0.9781\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.1784 - accuracy: 0.9844\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.1624 - accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.1471 - accuracy: 0.9906\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.1336 - accuracy: 0.9906\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.1210 - accuracy: 0.9937\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.1110 - accuracy: 0.9937\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.1022 - accuracy: 0.9969\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 0.0935 - accuracy: 0.9969\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.0858 - accuracy: 0.9969\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0791 - accuracy: 0.9969\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0735 - accuracy: 0.9969\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0676 - accuracy: 0.9969\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0629 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0545 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0507 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0478 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0393 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0369 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0353 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0279 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 54us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 60us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "[[12  0  0  0  0  0  0  0]\n",
      " [ 0  3  1  1  2  0  1  1]\n",
      " [ 0  0  5  1  0  0  0  1]\n",
      " [ 0  3  2  5  0  2  0  1]\n",
      " [ 0  1  0  0  6  1  1  0]\n",
      " [ 0  1  0  0  0 10  0  0]\n",
      " [ 0  1  0  0  0  1  5  3]\n",
      " [ 1  0  1  0  2  0  1  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.92      1.00      0.96        12\n",
      "     class 1       0.33      0.33      0.33         9\n",
      "     class 2       0.56      0.71      0.63         7\n",
      "     class 3       0.71      0.38      0.50        13\n",
      "     class 4       0.60      0.67      0.63         9\n",
      "     class 5       0.71      0.91      0.80        11\n",
      "     class 6       0.62      0.50      0.56        10\n",
      "     class 7       0.40      0.44      0.42         9\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.61      0.62      0.60        80\n",
      "weighted avg       0.63      0.62      0.62        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "#PCA + MLP (1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,108)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 390us/step - loss: 2.1251 - accuracy: 0.1656\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 1.8887 - accuracy: 0.2844\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 1.7037 - accuracy: 0.5875\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 1.5505 - accuracy: 0.7812\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 1.3974 - accuracy: 0.8875\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 1.2310 - accuracy: 0.9375\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 1.0358 - accuracy: 0.9563\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.8209 - accuracy: 0.9594\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.6167 - accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.4490 - accuracy: 0.9656\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.3268 - accuracy: 0.9688\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 0.2399 - accuracy: 0.9719\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.1855 - accuracy: 0.9719\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.1526 - accuracy: 0.9719\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.1294 - accuracy: 0.9750\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.1140 - accuracy: 0.9750\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.1024 - accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0943 - accuracy: 0.9781\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0869 - accuracy: 0.9812\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0815 - accuracy: 0.9781\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0763 - accuracy: 0.9812\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0722 - accuracy: 0.9844\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0678 - accuracy: 0.9844\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0644 - accuracy: 0.9844\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0609 - accuracy: 0.9844\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.96 - 0s 50us/step - loss: 0.0581 - accuracy: 0.9844\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.0561 - accuracy: 0.9875\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0531 - accuracy: 0.9906\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 62us/step - loss: 0.0511 - accuracy: 0.9906\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0491 - accuracy: 0.9906\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0477 - accuracy: 0.9906\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0456 - accuracy: 0.9906\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0439 - accuracy: 0.9906\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.0425 - accuracy: 0.9906\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0406 - accuracy: 0.9906\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0395 - accuracy: 0.9906\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 64us/step - loss: 0.0381 - accuracy: 0.9937\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0372 - accuracy: 0.9906\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 62us/step - loss: 0.0357 - accuracy: 0.9937\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0342 - accuracy: 0.9937\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0336 - accuracy: 0.9937\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0322 - accuracy: 0.9937\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0313 - accuracy: 0.9937\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0306 - accuracy: 0.9937\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0296 - accuracy: 0.9937\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0286 - accuracy: 0.9937\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0269 - accuracy: 0.9937\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0262 - accuracy: 0.9937\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0254 - accuracy: 0.9937\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0246 - accuracy: 0.9937\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0238 - accuracy: 0.9937\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0232 - accuracy: 0.9937\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0227 - accuracy: 0.9937\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0221 - accuracy: 0.9937\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0213 - accuracy: 0.9937\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 0.0206 - accuracy: 0.9937\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0202 - accuracy: 0.9969\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0195 - accuracy: 0.9969\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0191 - accuracy: 0.9969\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0185 - accuracy: 0.9969\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0181 - accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0176 - accuracy: 0.9969\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0172 - accuracy: 0.9969\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0168 - accuracy: 0.9969\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0163 - accuracy: 0.9969\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0160 - accuracy: 0.9969\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0156 - accuracy: 0.9969\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0152 - accuracy: 0.9969\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0147 - accuracy: 0.9969\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0141 - accuracy: 0.9969\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0138 - accuracy: 0.9969\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0134 - accuracy: 0.9969\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0131 - accuracy: 0.9969\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0128 - accuracy: 0.9969\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0125 - accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0122 - accuracy: 0.9969\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0119 - accuracy: 0.9969\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 46us/step - loss: 0.0115 - accuracy: 0.9969\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0114 - accuracy: 0.9969\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0110 - accuracy: 0.9969\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0111 - accuracy: 0.9969\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0106 - accuracy: 0.9969\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0105 - accuracy: 0.9969\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0100 - accuracy: 0.9969\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 0.0098 - accuracy: 0.9969\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0097 - accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 0.0091 - accuracy: 0.9969\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0089 - accuracy: 0.9969\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0087 - accuracy: 0.9969\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0086 - accuracy: 0.9969\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "[[ 7  1  1  0  0  0  0  0]\n",
      " [ 0  7  1  0  0  0  0  0]\n",
      " [ 0  0  9  0  0  0  1  0]\n",
      " [ 0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0]\n",
      " [ 0  0  1  0  0 10  0  0]\n",
      " [ 0  0  0  0  0  0 18  0]\n",
      " [ 0  0  0  0  0  0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.78      0.88         9\n",
      "     class 1       0.88      0.88      0.88         8\n",
      "     class 2       0.75      0.90      0.82        10\n",
      "     class 3       1.00      1.00      1.00         8\n",
      "     class 4       1.00      1.00      1.00         7\n",
      "     class 5       1.00      0.91      0.95        11\n",
      "     class 6       0.95      1.00      0.97        18\n",
      "     class 7       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.95      0.93      0.94        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "# LDA + MLP (2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 392us/step - loss: 1.8853 - accuracy: 0.2531\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 1.6960 - accuracy: 0.2812\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.5451 - accuracy: 0.4750\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 1.4064 - accuracy: 0.5562\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 1.2479 - accuracy: 0.6375\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 61us/step - loss: 1.0450 - accuracy: 0.6438\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 62us/step - loss: 0.8692 - accuracy: 0.6687\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.7194 - accuracy: 0.7906\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.5552 - accuracy: 0.9125\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.3803 - accuracy: 0.9750\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.2510 - accuracy: 0.9781\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 66us/step - loss: 0.1675 - accuracy: 0.9812\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.1269 - accuracy: 0.9812\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 0.1061 - accuracy: 0.9844\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0937 - accuracy: 0.9812\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0851 - accuracy: 0.9812\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.0783 - accuracy: 0.9844\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0735 - accuracy: 0.9875\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0688 - accuracy: 0.9875\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0655 - accuracy: 0.9875\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0615 - accuracy: 0.9875\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0585 - accuracy: 0.9875\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 59us/step - loss: 0.0556 - accuracy: 0.9875\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0534 - accuracy: 0.9875\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0512 - accuracy: 0.9875\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0486 - accuracy: 0.9906\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0468 - accuracy: 0.9906\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0447 - accuracy: 0.9906\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0427 - accuracy: 0.9906\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.0410 - accuracy: 0.9906\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0392 - accuracy: 0.9906\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0377 - accuracy: 0.9906\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0364 - accuracy: 0.9906\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0354 - accuracy: 0.9906\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0334 - accuracy: 0.9906\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0324 - accuracy: 0.9906\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0308 - accuracy: 0.9937\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0294 - accuracy: 0.9937\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0281 - accuracy: 0.9937\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0276 - accuracy: 0.9937\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0258 - accuracy: 0.9969\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 60us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 44us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "[[13  0  0  0  0  1  0  0]\n",
      " [ 0  7  0  0  1  0  0  0]\n",
      " [ 0  2  9  0  0  0  0  0]\n",
      " [ 0  0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  8  0  0]\n",
      " [ 1  0  0  0  0  0 10  0]\n",
      " [ 0  0  0  0  0  0  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.93      0.93      0.93        14\n",
      "     class 1       0.78      0.88      0.82         8\n",
      "     class 2       1.00      0.82      0.90        11\n",
      "     class 3       1.00      1.00      1.00         7\n",
      "     class 4       0.90      1.00      0.95         9\n",
      "     class 5       0.89      1.00      0.94         8\n",
      "     class 6       1.00      0.91      0.95        11\n",
      "     class 7       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.94      0.94      0.94        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KLDA + MLP (3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 448us/step - loss: 1.7824 - accuracy: 0.3906\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 95us/step - loss: 1.3647 - accuracy: 0.3625\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 95us/step - loss: 1.0747 - accuracy: 0.3406\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 110us/step - loss: 0.8697 - accuracy: 0.3969\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 114us/step - loss: 0.7543 - accuracy: 0.4156\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.6876 - accuracy: 0.6500\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.5332 - accuracy: 0.8250\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.3617 - accuracy: 0.9031\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 0.2979 - accuracy: 0.9125\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 0.2512 - accuracy: 0.9125\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.2494 - accuracy: 0.9094\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.2414 - accuracy: 0.9031\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 0.2194 - accuracy: 0.9219\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.2512 - accuracy: 0.9187\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 104us/step - loss: 0.1924 - accuracy: 0.9219\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1946 - accuracy: 0.9250\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 93us/step - loss: 0.2106 - accuracy: 0.9187\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.1906 - accuracy: 0.9281\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 96us/step - loss: 0.1769 - accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1900 - accuracy: 0.9281\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 86us/step - loss: 0.1869 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 91us/step - loss: 0.1705 - accuracy: 0.9375\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1718 - accuracy: 0.9438\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 87us/step - loss: 0.1833 - accuracy: 0.9375\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.1627 - accuracy: 0.9344\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.1628 - accuracy: 0.9375\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 100us/step - loss: 0.1656 - accuracy: 0.9375\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 0.1688 - accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 100us/step - loss: 0.1672 - accuracy: 0.9281\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 104us/step - loss: 0.1631 - accuracy: 0.9344\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1496 - accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1533 - accuracy: 0.9469\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 103us/step - loss: 0.1794 - accuracy: 0.9344\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1625 - accuracy: 0.9344\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.1448 - accuracy: 0.9469\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1428 - accuracy: 0.9469\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 97us/step - loss: 0.1326 - accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 96us/step - loss: 0.1339 - accuracy: 0.9438\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.1368 - accuracy: 0.9375\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 109us/step - loss: 0.1434 - accuracy: 0.9438\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1319 - accuracy: 0.9469\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1403 - accuracy: 0.9438\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.1286 - accuracy: 0.9531\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 109us/step - loss: 0.1373 - accuracy: 0.9469\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 107us/step - loss: 0.1277 - accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 95us/step - loss: 0.1286 - accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 114us/step - loss: 0.1229 - accuracy: 0.9531\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 113us/step - loss: 0.1195 - accuracy: 0.9563\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 104us/step - loss: 0.1336 - accuracy: 0.9531\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 0.1229 - accuracy: 0.9563\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.1377 - accuracy: 0.9438\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 103us/step - loss: 0.1189 - accuracy: 0.9531\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 96us/step - loss: 0.1361 - accuracy: 0.9531\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 0.1573 - accuracy: 0.9406\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.1264 - accuracy: 0.9531\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.1389 - accuracy: 0.9563\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 101us/step - loss: 0.1301 - accuracy: 0.9469\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 96us/step - loss: 0.1193 - accuracy: 0.9563\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 108us/step - loss: 0.1092 - accuracy: 0.9625\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 0.1183 - accuracy: 0.9594\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 101us/step - loss: 0.1115 - accuracy: 0.9594\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 103us/step - loss: 0.1113 - accuracy: 0.9594\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 101us/step - loss: 0.1091 - accuracy: 0.9594\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 91us/step - loss: 0.1236 - accuracy: 0.9563\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 104us/step - loss: 0.1093 - accuracy: 0.9531\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1351 - accuracy: 0.9563\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 104us/step - loss: 0.1046 - accuracy: 0.9594\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1098 - accuracy: 0.9656\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1027 - accuracy: 0.9594\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 108us/step - loss: 0.1019 - accuracy: 0.9625\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 103us/step - loss: 0.0979 - accuracy: 0.9688\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.0946 - accuracy: 0.9656\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.1057 - accuracy: 0.9656\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 108us/step - loss: 0.1086 - accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 100us/step - loss: 0.0988 - accuracy: 0.9688\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.0913 - accuracy: 0.9594\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 0.1059 - accuracy: 0.9594\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.0967 - accuracy: 0.9625\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 106us/step - loss: 0.1031 - accuracy: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.1098 - accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1078 - accuracy: 0.9594\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.1144 - accuracy: 0.9531\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 110us/step - loss: 0.0978 - accuracy: 0.9563\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 99us/step - loss: 0.1345 - accuracy: 0.9531\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 102us/step - loss: 0.1048 - accuracy: 0.9563\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.0853 - accuracy: 0.9750\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 107us/step - loss: 0.0881 - accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 105us/step - loss: 0.0989 - accuracy: 0.9688\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 98us/step - loss: 0.0952 - accuracy: 0.9625\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 95us/step - loss: 0.1008 - accuracy: 0.9625\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 103us/step - loss: 0.0934 - accuracy: 0.9688\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 101us/step - loss: 0.0913 - accuracy: 0.9656\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 91us/step - loss: 0.0861 - accuracy: 0.9719\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 88us/step - loss: 0.0965 - accuracy: 0.9563\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 85us/step - loss: 0.1151 - accuracy: 0.9563\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 88us/step - loss: 0.1105 - accuracy: 0.9594\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 84us/step - loss: 0.0854 - accuracy: 0.9688\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 82us/step - loss: 0.0845 - accuracy: 0.9656\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 84us/step - loss: 0.0861 - accuracy: 0.9656\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 85us/step - loss: 0.0758 - accuracy: 0.9750\n",
      "[[13  0  0  0  0  0  0  0]\n",
      " [ 0 10  2  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  8  1  0  1  0]\n",
      " [ 0  1  0  0 13  0  0  0]\n",
      " [ 0  0  0  0  0 11  0  0]\n",
      " [ 0  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        13\n",
      "     class 1       0.91      0.83      0.87        12\n",
      "     class 2       0.71      1.00      0.83         5\n",
      "     class 3       1.00      0.80      0.89        10\n",
      "     class 4       0.93      0.93      0.93        14\n",
      "     class 5       1.00      1.00      1.00        11\n",
      "     class 6       0.82      1.00      0.90         9\n",
      "     class 7       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.93        80\n",
      "   macro avg       0.92      0.92      0.92        80\n",
      "weighted avg       0.94      0.93      0.93        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VGG + MLP (4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n",
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 406us/step - loss: 1.4322 - accuracy: 0.6062\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 83us/step - loss: 0.5270 - accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 90us/step - loss: 0.1425 - accuracy: 0.9688\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.1023 - accuracy: 0.9656\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 73us/step - loss: 0.0941 - accuracy: 0.9625\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 79us/step - loss: 0.0631 - accuracy: 0.9750\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 77us/step - loss: 0.0513 - accuracy: 0.9906\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 88us/step - loss: 0.0416 - accuracy: 0.9906\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.0382 - accuracy: 0.9937\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0406 - accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0291 - accuracy: 0.9937\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.0274 - accuracy: 0.9906\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 80us/step - loss: 0.0230 - accuracy: 0.9937\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 67us/step - loss: 0.0232 - accuracy: 0.9937\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 65us/step - loss: 0.0200 - accuracy: 0.9937\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.0204 - accuracy: 0.9969\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 0.0145 - accuracy: 0.9969\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 96us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 83us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 88us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 87us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 80us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 79us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 77us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 82us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 79us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 82us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 77us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 73us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 74us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 72us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 80us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 85us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 81us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 66us/step - loss: 9.9818e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 9.7544e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 65us/step - loss: 9.4641e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 68us/step - loss: 9.2543e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 91us/step - loss: 8.9255e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 65us/step - loss: 8.9246e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 8.4710e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 67us/step - loss: 8.2755e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 66us/step - loss: 7.9806e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 66us/step - loss: 7.9286e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "320/320 [==============================] - 0s 68us/step - loss: 7.6106e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 67us/step - loss: 7.4907e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 7.3284e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 7.2882e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 6.8675e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 73us/step - loss: 6.8298e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 6.5944e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 6.3775e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 6.2419e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 75us/step - loss: 6.1816e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 80us/step - loss: 6.0081e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 5.9496e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 5.7595e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 71us/step - loss: 5.6985e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 78us/step - loss: 5.5487e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 79us/step - loss: 5.3279e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 69us/step - loss: 5.3082e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 76us/step - loss: 5.2702e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 73us/step - loss: 5.0532e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 70us/step - loss: 4.9770e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 4.8803e-04 - accuracy: 1.0000\n",
      "[[12  0  0  0  0  0  0  0]\n",
      " [ 0  9  0  0  0  0  1  0]\n",
      " [ 0  0 10  0  0  0  0  0]\n",
      " [ 0  0  0  7  0  0  1  0]\n",
      " [ 0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  1  0 12  0  0]\n",
      " [ 0  0  0  0  0  0  7  0]\n",
      " [ 0  0  0  0  0  0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        12\n",
      "     class 1       1.00      0.90      0.95        10\n",
      "     class 2       1.00      1.00      1.00        10\n",
      "     class 3       0.88      0.88      0.88         8\n",
      "     class 4       1.00      1.00      1.00         7\n",
      "     class 5       1.00      0.92      0.96        13\n",
      "     class 6       0.78      1.00      0.88         7\n",
      "     class 7       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.96      0.96      0.96        80\n",
      "weighted avg       0.97      0.96      0.96        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resnet + MLP (5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2048, 8 - 1) = 7 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 388us/step - loss: 2.0434 - accuracy: 0.0688\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.5588 - accuracy: 0.3656\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 1.2949 - accuracy: 0.7094\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 54us/step - loss: 1.0616 - accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 0.7822 - accuracy: 0.9812\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 66us/step - loss: 0.4939 - accuracy: 0.9969\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 59us/step - loss: 0.2724 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 60us/step - loss: 0.1493 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 67us/step - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0240 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 60us/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 38us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 42us/step - loss: 9.7702e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 9.5334e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 9.3453e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 9.1081e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 8.9120e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 8.7183e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 8.5325e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 8.3422e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 8.1578e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 7.9969e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 7.8265e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 7.6578e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 7.4874e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 7.3481e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 39us/step - loss: 7.2002e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 7.0508e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 39us/step - loss: 6.9144e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 6.7901e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 6.6381e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 39us/step - loss: 6.5233e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 6.3929e-04 - accuracy: 1.0000\n",
      "[[ 7  0  0  0  0  0  0  0]\n",
      " [ 0  7  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0]\n",
      " [ 0  0  0 11  0  0  0  0]\n",
      " [ 0  0  0  0 14  0  0  0]\n",
      " [ 0  0  0  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  0 13  0]\n",
      " [ 0  0  0  0  0  0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00         7\n",
      "     class 1       1.00      1.00      1.00         7\n",
      "     class 2       1.00      1.00      1.00        10\n",
      "     class 3       1.00      1.00      1.00        11\n",
      "     class 4       1.00      1.00      1.00        14\n",
      "     class 5       1.00      1.00      1.00         9\n",
      "     class 6       1.00      1.00      1.00        13\n",
      "     class 7       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Resnet + LDA + MLP (6)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,108)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 248us/step - loss: 2.0618 - accuracy: 0.1415\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 1.9908 - accuracy: 0.1974\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 56us/step - loss: 1.9311 - accuracy: 0.2886\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 56us/step - loss: 1.8705 - accuracy: 0.3557\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 55us/step - loss: 1.8061 - accuracy: 0.4469\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 1.7336 - accuracy: 0.5102\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 1.6509 - accuracy: 0.5493\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 1.5526 - accuracy: 0.5996\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 56us/step - loss: 1.4327 - accuracy: 0.6406\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 1.2855 - accuracy: 0.7020\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 1.1122 - accuracy: 0.7356\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.9263 - accuracy: 0.7821\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.7579 - accuracy: 0.8138\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.6142 - accuracy: 0.8659\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.5019 - accuracy: 0.8939\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.4074 - accuracy: 0.9218\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.3379 - accuracy: 0.9385\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.2787 - accuracy: 0.9665\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.2287 - accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.1905 - accuracy: 0.9851\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.1618 - accuracy: 0.9907\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.1363 - accuracy: 0.9944\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.1171 - accuracy: 0.9944\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.1006 - accuracy: 0.9963\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.0872 - accuracy: 0.9963\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0765 - accuracy: 0.9963\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0664 - accuracy: 0.9963\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0586 - accuracy: 0.9963\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0522 - accuracy: 0.9981\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 0.0464 - accuracy: 0.9981\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0413 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0371 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 49us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 55us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "[[ 4  2  0  2  2  0  1  0]\n",
      " [ 0  2  0  2  1  0  1  0]\n",
      " [ 0  0  6  3  1  0  1  2]\n",
      " [ 0  3  4 14  0  0  1  1]\n",
      " [ 3  0  5  1 12  0  2  3]\n",
      " [ 1  0  1  1  4  7  2  2]\n",
      " [ 2  0  2  3  0  4  8  1]\n",
      " [ 1  0  1  2  2  2  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.36      0.36      0.36        11\n",
      "     class 1       0.29      0.33      0.31         6\n",
      "     class 2       0.32      0.46      0.37        13\n",
      "     class 3       0.50      0.61      0.55        23\n",
      "     class 4       0.55      0.46      0.50        26\n",
      "     class 5       0.54      0.39      0.45        18\n",
      "     class 6       0.47      0.40      0.43        20\n",
      "     class 7       0.50      0.50      0.50        18\n",
      "\n",
      "    accuracy                           0.46       135\n",
      "   macro avg       0.44      0.44      0.43       135\n",
      "weighted avg       0.47      0.46      0.46       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "#PCA + MLP (1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,309)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1024, 8 - 1) = 7 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 244us/step - loss: 1.9711 - accuracy: 0.2402\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 1.6901 - accuracy: 0.5698\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 1.4615 - accuracy: 0.8399\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 1.1924 - accuracy: 0.9125\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.8486 - accuracy: 0.9404\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.5232 - accuracy: 0.9497\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.3164 - accuracy: 0.9590\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.2218 - accuracy: 0.9609\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.1799 - accuracy: 0.9665\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.1558 - accuracy: 0.9683\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.1415 - accuracy: 0.9702\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.1294 - accuracy: 0.9702\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.1212 - accuracy: 0.9721\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.1146 - accuracy: 0.9739\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.1059 - accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0999 - accuracy: 0.9721\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0937 - accuracy: 0.9739\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0884 - accuracy: 0.9758\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0847 - accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0795 - accuracy: 0.9777\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0763 - accuracy: 0.9758\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0711 - accuracy: 0.9777\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0683 - accuracy: 0.9814\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0646 - accuracy: 0.9814\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0627 - accuracy: 0.9814\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0591 - accuracy: 0.9851\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0559 - accuracy: 0.9870\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0539 - accuracy: 0.9870\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0511 - accuracy: 0.9888\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0495 - accuracy: 0.9888\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0478 - accuracy: 0.9926\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0448 - accuracy: 0.9907\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0423 - accuracy: 0.9926\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0408 - accuracy: 0.9926\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0394 - accuracy: 0.9926\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0370 - accuracy: 0.9926\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0355 - accuracy: 0.9926\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0335 - accuracy: 0.9926\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0322 - accuracy: 0.9926\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0307 - accuracy: 0.9926\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0301 - accuracy: 0.9963\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0286 - accuracy: 0.9963\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0272 - accuracy: 0.9981\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0259 - accuracy: 0.9981\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0249 - accuracy: 0.9981\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0237 - accuracy: 0.9981\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0226 - accuracy: 0.9981\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0219 - accuracy: 0.9981\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0211 - accuracy: 0.9981\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0158 - accuracy: 0.9981\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 44us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 37us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "[[11  0  0  1  0  0  0  0]\n",
      " [ 0  6  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  1  1]\n",
      " [ 0  0  0 17  1  0  0  1]\n",
      " [ 0  0  0  0 17  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  1]\n",
      " [ 0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  1  0  0  0 21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.92      0.96        12\n",
      "     class 1       1.00      1.00      1.00         6\n",
      "     class 2       1.00      0.91      0.95        23\n",
      "     class 3       0.89      0.89      0.89        19\n",
      "     class 4       0.94      1.00      0.97        17\n",
      "     class 5       1.00      0.94      0.97        16\n",
      "     class 6       0.95      1.00      0.98        20\n",
      "     class 7       0.88      0.95      0.91        22\n",
      "\n",
      "    accuracy                           0.95       135\n",
      "   macro avg       0.96      0.95      0.95       135\n",
      "weighted avg       0.95      0.95      0.95       135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "# LDA + MLP (2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,309)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(1024, 8 - 1) = 7 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 236us/step - loss: 1.9927 - accuracy: 0.2123\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 1.4794 - accuracy: 0.3315\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 1.1396 - accuracy: 0.6816\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.8086 - accuracy: 0.9125\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.4183 - accuracy: 0.9609\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 0.2093 - accuracy: 0.9832\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.1337 - accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0940 - accuracy: 0.9888\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0761 - accuracy: 0.9888\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0659 - accuracy: 0.9888\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0587 - accuracy: 0.9888\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0532 - accuracy: 0.9888\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0486 - accuracy: 0.9888\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0449 - accuracy: 0.9888\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0407 - accuracy: 0.9888\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0375 - accuracy: 0.9888\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0343 - accuracy: 0.9888\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0319 - accuracy: 0.9888\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 57us/step - loss: 0.0293 - accuracy: 0.9926\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0277 - accuracy: 0.9926\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0256 - accuracy: 0.9926\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0235 - accuracy: 0.9944\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0226 - accuracy: 0.9944\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 56us/step - loss: 0.0210 - accuracy: 0.9944\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0197 - accuracy: 0.9944\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0174 - accuracy: 0.9944\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0164 - accuracy: 0.9963\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0153 - accuracy: 0.9963\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0147 - accuracy: 0.9963\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0139 - accuracy: 0.9981\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0130 - accuracy: 0.9981\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0124 - accuracy: 0.9981\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0117 - accuracy: 0.9981\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.0111 - accuracy: 0.9981\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 47us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 9.3154e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 9.4287e-04 - accuracy: 1.0000\n",
      "[[14  0  0  1  0  0  0  0]\n",
      " [ 0  5  0  0  0  0  0  0]\n",
      " [ 0  0 11  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  1  0]\n",
      " [ 0  0  0  0 25  0  0  0]\n",
      " [ 0  0  0  0  0 21  0  0]\n",
      " [ 0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  1 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.93      0.97        15\n",
      "     class 1       1.00      1.00      1.00         5\n",
      "     class 2       1.00      1.00      1.00        11\n",
      "     class 3       0.94      0.94      0.94        18\n",
      "     class 4       1.00      1.00      1.00        25\n",
      "     class 5       1.00      1.00      1.00        21\n",
      "     class 6       0.91      1.00      0.95        20\n",
      "     class 7       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KLDA + MLP (3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,8)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 295us/step - loss: 1.7140 - accuracy: 0.4246\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 101us/step - loss: 1.2759 - accuracy: 0.5382\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 123us/step - loss: 0.9294 - accuracy: 0.6574\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 121us/step - loss: 0.8319 - accuracy: 0.6797\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.7939 - accuracy: 0.7188\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.7900 - accuracy: 0.7114\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.7799 - accuracy: 0.7132\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.7685 - accuracy: 0.7467\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.7596 - accuracy: 0.7281\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 96us/step - loss: 0.7471 - accuracy: 0.7114\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.7431 - accuracy: 0.7225\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.7232 - accuracy: 0.7393\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.7333 - accuracy: 0.7412\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.7248 - accuracy: 0.7337\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.7055 - accuracy: 0.7430\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.7034 - accuracy: 0.7467\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.6970 - accuracy: 0.7318\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.6945 - accuracy: 0.7430\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.6920 - accuracy: 0.7486\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 113us/step - loss: 0.6900 - accuracy: 0.7449\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 120us/step - loss: 0.6901 - accuracy: 0.7505\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 108us/step - loss: 0.6947 - accuracy: 0.7505\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.6718 - accuracy: 0.7523\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.7098 - accuracy: 0.7430\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 95us/step - loss: 0.7003 - accuracy: 0.7337\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.6819 - accuracy: 0.7542\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.6576 - accuracy: 0.7412\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.6628 - accuracy: 0.7505\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.6549 - accuracy: 0.7579\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 101us/step - loss: 0.6551 - accuracy: 0.7598\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.6375 - accuracy: 0.7691\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.6560 - accuracy: 0.7616\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 122us/step - loss: 0.6358 - accuracy: 0.7654\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 98us/step - loss: 0.6447 - accuracy: 0.7505\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.6420 - accuracy: 0.7747\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.6411 - accuracy: 0.7561\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 138us/step - loss: 0.6479 - accuracy: 0.7505\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 115us/step - loss: 0.6335 - accuracy: 0.7598\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.6196 - accuracy: 0.7635\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 104us/step - loss: 0.6265 - accuracy: 0.7672\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.6283 - accuracy: 0.7672\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 102us/step - loss: 0.6212 - accuracy: 0.7840\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.6276 - accuracy: 0.7616\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 118us/step - loss: 0.6334 - accuracy: 0.7542\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 124us/step - loss: 0.6158 - accuracy: 0.7691\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.6087 - accuracy: 0.7747\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 117us/step - loss: 0.6595 - accuracy: 0.7598\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.6229 - accuracy: 0.7635\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 103us/step - loss: 0.6189 - accuracy: 0.7765\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.6279 - accuracy: 0.7616\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.6183 - accuracy: 0.7765\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 106us/step - loss: 0.6038 - accuracy: 0.7728\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 119us/step - loss: 0.5941 - accuracy: 0.7709\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 119us/step - loss: 0.5883 - accuracy: 0.7877\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.6086 - accuracy: 0.7654\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.5860 - accuracy: 0.7691\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.5879 - accuracy: 0.7803\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 117us/step - loss: 0.5923 - accuracy: 0.7765\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.6176 - accuracy: 0.7709\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.6165 - accuracy: 0.7635\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 122us/step - loss: 0.5816 - accuracy: 0.7765\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.5886 - accuracy: 0.7635\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5949 - accuracy: 0.7709\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 113us/step - loss: 0.5756 - accuracy: 0.7654\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 117us/step - loss: 0.5687 - accuracy: 0.7877\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.5647 - accuracy: 0.7914\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.5610 - accuracy: 0.7877\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.5599 - accuracy: 0.7914\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.5649 - accuracy: 0.7803\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 110us/step - loss: 0.5541 - accuracy: 0.7858\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.5572 - accuracy: 0.7728\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.5449 - accuracy: 0.7877\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.5624 - accuracy: 0.7765\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5698 - accuracy: 0.7709\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.5633 - accuracy: 0.7858\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 109us/step - loss: 0.5425 - accuracy: 0.7896\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 127us/step - loss: 0.5561 - accuracy: 0.7858\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.5507 - accuracy: 0.7989\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 121us/step - loss: 0.5439 - accuracy: 0.7970\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 0s 100us/step - loss: 0.5510 - accuracy: 0.7952\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 97us/step - loss: 0.5544 - accuracy: 0.7821\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 94us/step - loss: 0.5400 - accuracy: 0.8007\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 93us/step - loss: 0.5314 - accuracy: 0.8026\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 88us/step - loss: 0.5221 - accuracy: 0.8138\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.5303 - accuracy: 0.7877\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.5308 - accuracy: 0.8045\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.5340 - accuracy: 0.7896\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 128us/step - loss: 0.5177 - accuracy: 0.8045\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 111us/step - loss: 0.5239 - accuracy: 0.7896\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5199 - accuracy: 0.7952\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5109 - accuracy: 0.8101\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 127us/step - loss: 0.5230 - accuracy: 0.7896\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 126us/step - loss: 0.5037 - accuracy: 0.8063\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 114us/step - loss: 0.5039 - accuracy: 0.8045\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 105us/step - loss: 0.5062 - accuracy: 0.8082\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 120us/step - loss: 0.5088 - accuracy: 0.8138\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 116us/step - loss: 0.5224 - accuracy: 0.8007\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 112us/step - loss: 0.5001 - accuracy: 0.8194\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 99us/step - loss: 0.5309 - accuracy: 0.7914\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 121us/step - loss: 0.4978 - accuracy: 0.8119\n",
      "[[ 7  0  3  0  0  0  0  0]\n",
      " [ 2  3  0  1  0  0  1  1]\n",
      " [ 1  0  6  0  2  0  0  2]\n",
      " [ 1  0  3 14  3  0  1  1]\n",
      " [ 2  1  4  1 10  0  0  2]\n",
      " [ 0  0  0  0  1 18  1  2]\n",
      " [ 0  0  0  0  0  1 24  0]\n",
      " [ 0  0  2  0  1  0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.54      0.70      0.61        10\n",
      "     class 1       0.75      0.38      0.50         8\n",
      "     class 2       0.33      0.55      0.41        11\n",
      "     class 3       0.88      0.61      0.72        23\n",
      "     class 4       0.59      0.50      0.54        20\n",
      "     class 5       0.95      0.82      0.88        22\n",
      "     class 6       0.89      0.96      0.92        25\n",
      "     class 7       0.62      0.81      0.70        16\n",
      "\n",
      "    accuracy                           0.70       135\n",
      "   macro avg       0.69      0.66      0.66       135\n",
      "weighted avg       0.74      0.70      0.71       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VGG + MLP (4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 266us/step - loss: 1.3676 - accuracy: 0.7672\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.3833 - accuracy: 0.9255\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.1135 - accuracy: 0.9646\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 79us/step - loss: 0.0772 - accuracy: 0.9739\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.0645 - accuracy: 0.9832\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0603 - accuracy: 0.9851\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0419 - accuracy: 0.9907\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.0387 - accuracy: 0.9907\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.0316 - accuracy: 0.9907\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0289 - accuracy: 0.9944\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.0331 - accuracy: 0.9944\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 82us/step - loss: 0.0242 - accuracy: 0.9944\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.0243 - accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.0221 - accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 83us/step - loss: 0.0154 - accuracy: 0.9981\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0138 - accuracy: 0.9981\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 69us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 69us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 68us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 70us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 76us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 70us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 70us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 81us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 71us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 78us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 70us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 80us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 70us/step - loss: 9.8458e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 69us/step - loss: 9.6789e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 66us/step - loss: 8.9348e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 66us/step - loss: 9.2281e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 79us/step - loss: 8.8467e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 81us/step - loss: 8.3703e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 8.0973e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 7.9139e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 7.7864e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 78us/step - loss: 7.2953e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 82us/step - loss: 7.1483e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 81us/step - loss: 7.0154e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 85us/step - loss: 6.7598e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 80us/step - loss: 6.5034e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 79us/step - loss: 6.3135e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 79us/step - loss: 6.1209e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 77us/step - loss: 5.9886e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 72us/step - loss: 6.0335e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 80us/step - loss: 5.6725e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 82us/step - loss: 5.4519e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 5.4808e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 64us/step - loss: 5.2974e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 61us/step - loss: 5.1802e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 61us/step - loss: 5.0528e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 66us/step - loss: 4.9635e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 63us/step - loss: 4.7323e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 67us/step - loss: 4.7240e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 68us/step - loss: 4.6279e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 76us/step - loss: 4.4497e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 4.4269e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 82us/step - loss: 4.1866e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 83us/step - loss: 4.1155e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 78us/step - loss: 4.0695e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 3.8979e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 81us/step - loss: 3.8556e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 3.8419e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 78us/step - loss: 3.7664e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 73us/step - loss: 3.6902e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 74us/step - loss: 3.5663e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 83us/step - loss: 3.6081e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 75us/step - loss: 3.3699e-04 - accuracy: 1.0000\n",
      "[[ 7  0  0  1  0  0  0  0]\n",
      " [ 0 11  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  1  0  0  0]\n",
      " [ 0  0  0 24  0  0  0  0]\n",
      " [ 0  0  0  0 16  0  0  0]\n",
      " [ 0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0 16  0]\n",
      " [ 0  0  0  0  1  0  0 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.88      0.93         8\n",
      "     class 1       1.00      1.00      1.00        11\n",
      "     class 2       1.00      0.94      0.97        17\n",
      "     class 3       0.96      1.00      0.98        24\n",
      "     class 4       0.89      1.00      0.94        16\n",
      "     class 5       1.00      1.00      1.00        23\n",
      "     class 6       1.00      1.00      1.00        16\n",
      "     class 7       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.97      0.97       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resnet + MLP (5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(2048, 8 - 1) = 7 components.\n",
      "  ChangedBehaviorWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 258us/step - loss: 2.1139 - accuracy: 0.2626\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 1.3761 - accuracy: 0.7058\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 1.0008 - accuracy: 0.8659\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 58us/step - loss: 0.6553 - accuracy: 0.9926\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.3493 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 0.1546 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0609 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.0329 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 55us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 9.5994e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 9.2314e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 8.8824e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 8.5509e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 8.2256e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 7.9242e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 7.6511e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 7.3613e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 7.1158e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 6.8646e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 6.6470e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 6.4258e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 6.2237e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 6.0177e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 5.8384e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 5.6524e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 5.4782e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 5.3176e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 5.1704e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 5.0205e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 4.8758e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 4.7434e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 4.6093e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 4.4835e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 4.3786e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 4.2519e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 4.1506e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 4.0328e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 3.9400e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 3.8321e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 3.7387e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 3.6508e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 3.5633e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 49us/step - loss: 3.4748e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 3.3904e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 3.3143e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 3.2343e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 3.1600e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 3.0899e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 3.0179e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 2.9503e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.8843e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.8186e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 2.7560e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.7007e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 2.6396e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.5840e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 2.5319e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.4755e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 2.4225e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 2.3759e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 2.3251e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 2.2779e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 2.2319e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 2.1923e-04 - accuracy: 1.0000\n",
      "[[11  0  0  0  0  0  0  0]\n",
      " [ 0 11  0  0  0  0  0  0]\n",
      " [ 0  0 19  0  0  0  0  0]\n",
      " [ 0  0  0 17  0  0  0  0]\n",
      " [ 0  0  0  0 24  0  0  0]\n",
      " [ 0  0  0  0  0 16  0  0]\n",
      " [ 0  0  0  0  0  0 21  0]\n",
      " [ 0  0  0  0  0  0  0 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00        11\n",
      "     class 1       1.00      1.00      1.00        11\n",
      "     class 2       1.00      1.00      1.00        19\n",
      "     class 3       1.00      1.00      1.00        17\n",
      "     class 4       1.00      1.00      1.00        24\n",
      "     class 5       1.00      1.00      1.00        16\n",
      "     class 6       1.00      1.00      1.00        21\n",
      "     class 7       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00       135\n",
      "   macro avg       1.00      1.00      1.00       135\n",
      "weighted avg       1.00      1.00      1.00       135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Resnet + LDA + MLP (6)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,8)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "# MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "import sklearn as sk\n",
    "class Classifier1():\n",
    "    def __init__(self, X_train):\n",
    "#         super.__init__()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(35, input_dim=X_train.shape[1], activation='relu'))# layer 1 neuron 1000\n",
    "        model.add(Dense(35, activation='relu'))# layer 2 neuron 1000\n",
    "        model.add(Dense(15, activation='sigmoid'))# output layer\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        predict = model.predict(X)\n",
    "        return prediction\n",
    "        \n",
    "    def confusion_matrix(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or classifier) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        confusion_matrix = sk.metrics.confusion_matrix(y, pred)\n",
    "        return confusion_matrix\n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train,epochs=100)\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict_classes(X_validate)\n",
    "        # Create a confusion matrix\n",
    "        confusion_matrix = self.confusion_matrix(y_pred, y_validate)\n",
    "        # Calculate Validation accuracy \n",
    "        # Calculate precision and recall \n",
    "        # Calculate F1-score \n",
    "#         target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6',  'class 7', 'class 8', 'class 9', 'class 10', 'class 11', 'class 12','class 13', 'class 14']\n",
    "        classification_report = sk.metrics.classification_report(y_validate, y_pred)\n",
    "        return confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 886us/step - loss: 2.7534 - accuracy: 0.0985\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 2.6886 - accuracy: 0.1061\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 2.6392 - accuracy: 0.1136\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 2.5980 - accuracy: 0.1136\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 2.5589 - accuracy: 0.1515\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 2.5231 - accuracy: 0.1742\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 2.4878 - accuracy: 0.2045\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 2.4546 - accuracy: 0.2348\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 2.4208 - accuracy: 0.2273\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 82us/step - loss: 2.3867 - accuracy: 0.2424\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 2.3520 - accuracy: 0.2879\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 2.3164 - accuracy: 0.3106\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 2.2787 - accuracy: 0.3485\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 2.2372 - accuracy: 0.4091\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 2.1949 - accuracy: 0.4470\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 2.1467 - accuracy: 0.4848\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 2.0951 - accuracy: 0.5455\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 2.0378 - accuracy: 0.5985\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 1.9759 - accuracy: 0.6364\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 96us/step - loss: 1.9046 - accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.8262 - accuracy: 0.7045\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.7385 - accuracy: 0.7424\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.6411 - accuracy: 0.7727\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.5327 - accuracy: 0.7803\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 1.4218 - accuracy: 0.7955\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 1.3061 - accuracy: 0.8258\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.1899 - accuracy: 0.8485\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.0765 - accuracy: 0.8864\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.9679 - accuracy: 0.9091\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.8677 - accuracy: 0.9318\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.7749 - accuracy: 0.9470\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.6910 - accuracy: 0.9470\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 0.6129 - accuracy: 0.9470\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.5402 - accuracy: 0.9621\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.4784 - accuracy: 0.9773\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.4273 - accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.3781 - accuracy: 0.9848\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.3371 - accuracy: 0.9848\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.3023 - accuracy: 0.9848\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.2731 - accuracy: 0.9848\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.2455 - accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.2237 - accuracy: 0.9848\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.2037 - accuracy: 0.9924\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.1842 - accuracy: 0.9924\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 0.1670 - accuracy: 0.9924\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.1523 - accuracy: 0.9924\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.1392 - accuracy: 0.9924\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.1275 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.1169 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.1086 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.1010 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0936 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0874 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 0.0814 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0760 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0713 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0670 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0595 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0534 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0480 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0456 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0412 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 0.0393 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.0344 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 0.0288 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0238 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 65us/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 3 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      0.60      0.75         5\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      0.75      0.86         4\n",
      "           6       1.00      0.75      0.86         4\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      0.67      0.80         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       0.50      1.00      0.67         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.85        33\n",
      "   macro avg       0.80      0.77      0.77        33\n",
      "weighted avg       0.96      0.85      0.89        33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "#PCA + MLP (1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,62)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 892us/step - loss: 2.7520 - accuracy: 0.1136\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 2.6120 - accuracy: 0.1742\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 2.5072 - accuracy: 0.2045\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 2.4155 - accuracy: 0.2273\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 2.3386 - accuracy: 0.2727\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 2.2697 - accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 2.2048 - accuracy: 0.4015\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 2.1400 - accuracy: 0.4621\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 2.0750 - accuracy: 0.4848\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 2.0091 - accuracy: 0.4773\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.9412 - accuracy: 0.4848\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 1.8708 - accuracy: 0.4924\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.7941 - accuracy: 0.5455\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.7097 - accuracy: 0.6439\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.6145 - accuracy: 0.6970\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 1.5056 - accuracy: 0.7348\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 1.3854 - accuracy: 0.7803\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.2573 - accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.1286 - accuracy: 0.8561\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.9934 - accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.8570 - accuracy: 0.9091\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.7270 - accuracy: 0.9242\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.6105 - accuracy: 0.9621\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.5085 - accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 0.4303 - accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.3611 - accuracy: 0.9848\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.3023 - accuracy: 0.9924\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.2552 - accuracy: 0.9924\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.2174 - accuracy: 0.9924\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.1870 - accuracy: 0.9924\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.1627 - accuracy: 0.9924\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.1431 - accuracy: 0.9924\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.1268 - accuracy: 0.9924\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.1140 - accuracy: 0.9924\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.1035 - accuracy: 0.9924\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0947 - accuracy: 0.9924\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0863 - accuracy: 0.9924\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0808 - accuracy: 0.9924\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.0766 - accuracy: 0.9924\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0711 - accuracy: 0.9924\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0663 - accuracy: 0.9924\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0626 - accuracy: 0.9924\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0593 - accuracy: 0.9924\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0563 - accuracy: 0.9924\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0538 - accuracy: 0.9924\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0504 - accuracy: 0.9924\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0484 - accuracy: 0.9924\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0468 - accuracy: 0.9924\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0443 - accuracy: 0.9924\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0428 - accuracy: 0.9924\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0407 - accuracy: 0.9924\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0389 - accuracy: 0.9924\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0373 - accuracy: 0.9924\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0364 - accuracy: 0.9924\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 53us/step - loss: 0.0350 - accuracy: 0.9924\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0338 - accuracy: 0.9924\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0325 - accuracy: 0.9924\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.0346 - accuracy: 0.9924\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0282 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0271 - accuracy: 0.9924\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0290 - accuracy: 0.9924\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0280 - accuracy: 0.9924\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0260 - accuracy: 0.9924\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 59us/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 52us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split to train your classifier \n",
    "# LDA + MLP (2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 943us/step - loss: 2.6572 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 2.5238 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 2.4281 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 2.3455 - accuracy: 0.0076\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 2.2762 - accuracy: 0.0227\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 2.2132 - accuracy: 0.0379\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 2.1519 - accuracy: 0.0606\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 2.0917 - accuracy: 0.0758\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 87us/step - loss: 2.0312 - accuracy: 0.1212\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 1.9661 - accuracy: 0.1515\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 1.8961 - accuracy: 0.1818\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 91us/step - loss: 1.8191 - accuracy: 0.2045\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 1.7319 - accuracy: 0.2273\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 1.6315 - accuracy: 0.2500\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 1.5234 - accuracy: 0.2652\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.4167 - accuracy: 0.3106\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 1.3149 - accuracy: 0.3712\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 1.2139 - accuracy: 0.4167\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 1.1039 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 0.9842 - accuracy: 0.5530\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 92us/step - loss: 0.8661 - accuracy: 0.6288\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.7624 - accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.6641 - accuracy: 0.7424\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.5720 - accuracy: 0.7727\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.4821 - accuracy: 0.8636\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.3964 - accuracy: 0.9015\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.3329 - accuracy: 0.9773\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.2881 - accuracy: 0.9924\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.2454 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.2014 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.1628 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.1342 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0871 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 0.0709 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.0595 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 0.0242 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 97us/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 54us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 81us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "[[3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 5 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         3\n",
      "          11       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KLDA + MLP (3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,8)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 942us/step - loss: 2.6128 - accuracy: 0.1439\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 130us/step - loss: 2.3261 - accuracy: 0.2197\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 131us/step - loss: 2.1703 - accuracy: 0.1970\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 145us/step - loss: 2.0357 - accuracy: 0.1742\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 1.9350 - accuracy: 0.1742\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 140us/step - loss: 1.8333 - accuracy: 0.1894\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 151us/step - loss: 1.7293 - accuracy: 0.1818\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 140us/step - loss: 1.6287 - accuracy: 0.1894\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 131us/step - loss: 1.5536 - accuracy: 0.2348\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 1.4756 - accuracy: 0.2121\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 129us/step - loss: 1.4098 - accuracy: 0.2652\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 152us/step - loss: 1.3071 - accuracy: 0.3712\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 143us/step - loss: 1.2172 - accuracy: 0.4773\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 132us/step - loss: 1.1344 - accuracy: 0.4697\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 137us/step - loss: 1.0909 - accuracy: 0.5076\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 152us/step - loss: 0.9477 - accuracy: 0.6061\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 137us/step - loss: 0.8899 - accuracy: 0.6212\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.8898 - accuracy: 0.6061\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.8209 - accuracy: 0.6288\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 118us/step - loss: 0.7781 - accuracy: 0.6742\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 129us/step - loss: 0.7836 - accuracy: 0.7121\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 124us/step - loss: 0.7452 - accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 147us/step - loss: 0.7938 - accuracy: 0.6591\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.7148 - accuracy: 0.7121\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 138us/step - loss: 0.6675 - accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 151us/step - loss: 0.6577 - accuracy: 0.7424\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 173us/step - loss: 0.6949 - accuracy: 0.7197\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 141us/step - loss: 0.7782 - accuracy: 0.7576\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 148us/step - loss: 0.6116 - accuracy: 0.8106\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 118us/step - loss: 0.6219 - accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 142us/step - loss: 0.5650 - accuracy: 0.7803\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.5044 - accuracy: 0.8409\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 145us/step - loss: 0.5431 - accuracy: 0.8106\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 134us/step - loss: 0.5064 - accuracy: 0.7879\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 122us/step - loss: 0.4707 - accuracy: 0.8409\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 0.5774 - accuracy: 0.7727\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.5080 - accuracy: 0.8106\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.4439 - accuracy: 0.8485\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 0.4609 - accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 126us/step - loss: 0.5125 - accuracy: 0.8106\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 124us/step - loss: 0.5519 - accuracy: 0.8106\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 127us/step - loss: 0.4693 - accuracy: 0.8409\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.4498 - accuracy: 0.8636\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.4394 - accuracy: 0.8788\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 127us/step - loss: 0.4177 - accuracy: 0.8636\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 117us/step - loss: 0.3887 - accuracy: 0.8712\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 129us/step - loss: 0.3724 - accuracy: 0.8788\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.3533 - accuracy: 0.8939\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 125us/step - loss: 0.3509 - accuracy: 0.8712\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 130us/step - loss: 0.3277 - accuracy: 0.8939\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 145us/step - loss: 0.3180 - accuracy: 0.8939\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 116us/step - loss: 0.3226 - accuracy: 0.8864\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 0.3215 - accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 126us/step - loss: 0.3178 - accuracy: 0.8939\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 119us/step - loss: 0.3371 - accuracy: 0.9091\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 0.3164 - accuracy: 0.8939\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 138us/step - loss: 0.2970 - accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.3187 - accuracy: 0.9015\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 133us/step - loss: 0.2979 - accuracy: 0.9015\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 0.2884 - accuracy: 0.8864\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.2697 - accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.3069 - accuracy: 0.9091\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.3049 - accuracy: 0.9015\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 127us/step - loss: 0.2687 - accuracy: 0.9242\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 140us/step - loss: 0.3657 - accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 134us/step - loss: 0.3185 - accuracy: 0.9091\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 130us/step - loss: 0.3047 - accuracy: 0.8864\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 0.4020 - accuracy: 0.8561\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.3252 - accuracy: 0.8712\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 153us/step - loss: 0.2882 - accuracy: 0.8788\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 153us/step - loss: 0.2726 - accuracy: 0.8939\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 135us/step - loss: 0.2500 - accuracy: 0.9394\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 133us/step - loss: 0.2670 - accuracy: 0.9015\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 152us/step - loss: 0.2657 - accuracy: 0.9015\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 143us/step - loss: 0.3053 - accuracy: 0.8939\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 141us/step - loss: 0.2668 - accuracy: 0.9015\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 121us/step - loss: 0.2543 - accuracy: 0.9091\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 141us/step - loss: 0.2401 - accuracy: 0.9318\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 128us/step - loss: 0.2010 - accuracy: 0.9470\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.2071 - accuracy: 0.9394\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 136us/step - loss: 0.1971 - accuracy: 0.9545\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 128us/step - loss: 0.1938 - accuracy: 0.9545\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 133us/step - loss: 0.1860 - accuracy: 0.9545\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 130us/step - loss: 0.1860 - accuracy: 0.9545\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 123us/step - loss: 0.1731 - accuracy: 0.9470\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 111us/step - loss: 0.1814 - accuracy: 0.9394\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 117us/step - loss: 0.2276 - accuracy: 0.9394\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 112us/step - loss: 0.2111 - accuracy: 0.9545\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 112us/step - loss: 0.1990 - accuracy: 0.9470\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 139us/step - loss: 0.1940 - accuracy: 0.9545\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 143us/step - loss: 0.1678 - accuracy: 0.9621\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 132us/step - loss: 0.1640 - accuracy: 0.9545\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 112us/step - loss: 0.1579 - accuracy: 0.9621\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 115us/step - loss: 0.1655 - accuracy: 0.9545\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 107us/step - loss: 0.1800 - accuracy: 0.9545\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 112us/step - loss: 0.1586 - accuracy: 0.9773\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 109us/step - loss: 0.1592 - accuracy: 0.9697\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 116us/step - loss: 0.1454 - accuracy: 0.9697\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 113us/step - loss: 0.1674 - accuracy: 0.9470\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 0.1443 - accuracy: 0.9470\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 2 0 0 1 0]\n",
      " [0 0 0 3 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 1 0 0 1 0]\n",
      " [0 1 1 0 0 0 0 2 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.40      0.40      0.40         5\n",
      "           3       0.75      0.75      0.75         4\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.50      0.67         4\n",
      "           8       1.00      0.50      0.67         4\n",
      "           9       0.33      1.00      0.50         2\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       0.33      1.00      0.50         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.64        33\n",
      "   macro avg       0.60      0.60      0.56        33\n",
      "weighted avg       0.73      0.64      0.64        33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# VGG + MLP (4)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n",
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 859us/step - loss: 2.4332 - accuracy: 0.3106\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 108us/step - loss: 1.8456 - accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 1.3733 - accuracy: 0.7348\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 0.9111 - accuracy: 0.8182\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 0.4847 - accuracy: 0.9091\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.2341 - accuracy: 0.9545\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 103us/step - loss: 0.1198 - accuracy: 0.9924\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 110us/step - loss: 0.0514 - accuracy: 0.9924\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 117us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 102us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 96us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 103us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 114us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 111us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 108us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 108us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 109us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 111us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 104us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 100us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 95us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 95us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 100us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 110us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 100us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 104us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 102us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 98us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 95us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 104us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 97us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 109us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 100us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 97us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 104us/step - loss: 9.5550e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 9.1975e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 97us/step - loss: 9.0256e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 8.7284e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 8.5103e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 96us/step - loss: 8.2422e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 8.0336e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 7.8865e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 7.6928e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 99us/step - loss: 7.5581e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 7.4085e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 7.2309e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 7.2520e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 87us/step - loss: 7.2595e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 7.0668e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 6.8916e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 6.6127e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 6.4163e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 6.2902e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 6.1344e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 6.0095e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 5.8834e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 5.7120e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 5.7494e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 5.6786e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 94us/step - loss: 5.5314e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 5.4169e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 5.2896e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 5.1462e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 86us/step - loss: 5.1191e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 90us/step - loss: 5.0238e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "132/132 [==============================] - 0s 87us/step - loss: 4.9399e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 4.7786e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 4.6977e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 4.6223e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 4.5511e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 4.4606e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 4.3792e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 4.3002e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 4.2424e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 4.1748e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 4.1055e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 4.0411e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 91us/step - loss: 3.9724e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 3.9330e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 91us/step - loss: 3.8334e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 3.8589e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 93us/step - loss: 3.8343e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 3.7909e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 84us/step - loss: 3.7012e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 3.6388e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 3.5468e-04 - accuracy: 1.0000\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 5 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resnet + MLP (5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 815us/step - loss: 3.4341 - accuracy: 0.0530\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 2.9783 - accuracy: 0.0379\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 2.6544 - accuracy: 0.0455\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 2.4447 - accuracy: 0.0758\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 2.2677 - accuracy: 0.0833\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 2.1625 - accuracy: 0.1061\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 2.0847 - accuracy: 0.1364\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 2.0191 - accuracy: 0.1818\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 1.9554 - accuracy: 0.2045\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 1.8949 - accuracy: 0.2273\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.8357 - accuracy: 0.2727\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 1.7778 - accuracy: 0.3030\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 81us/step - loss: 1.7203 - accuracy: 0.3258\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 1.6615 - accuracy: 0.3485\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 1.6012 - accuracy: 0.3712\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 80us/step - loss: 1.5374 - accuracy: 0.4091\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 1.4755 - accuracy: 0.4242\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 1.4101 - accuracy: 0.4621\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 88us/step - loss: 1.3385 - accuracy: 0.5152\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 89us/step - loss: 1.2565 - accuracy: 0.5758\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 1.1498 - accuracy: 0.7045\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 82us/step - loss: 1.0197 - accuracy: 0.7273\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.8837 - accuracy: 0.7424\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.7545 - accuracy: 0.7652\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.6552 - accuracy: 0.8258\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.5599 - accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.4896 - accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.4269 - accuracy: 0.9318\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.3656 - accuracy: 0.9318\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.3101 - accuracy: 0.9242\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.2707 - accuracy: 0.9318\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.2372 - accuracy: 0.9470\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.2100 - accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.1825 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.1485 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.1208 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 52us/step - loss: 0.1049 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0905 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - ETA: 0s - loss: 0.0644 - accuracy: 1.00 - 0s 70us/step - loss: 0.0617 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0494 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0399 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0316 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 85us/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0209 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 64us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 51us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 52us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 54us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "[[2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         1\n",
      "           9       1.00      1.00      1.00         4\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         3\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resnet + LDA + MLP (6)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,8)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print(conf_mat)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For IMFDB\n",
      "\n",
      "  Features used Reduced Dimension Space Classification error Accuracy F1-Score\n",
      "0           PCA                     108                  0.0      0.7     0.69\n",
      "1           LDA                     108                  0.0     0.94     0.93\n",
      "2         K-LDA                     108                  0.0     0.95     0.95\n",
      "3           VGG                       -                 0.03     0.88     0.88\n",
      "4        Resnet                       -                 0.00     0.95     0.95\n",
      "5  Resnet + LDA                     108                 0.00     1.00     1.00\n",
      "\n",
      "\n",
      "For IIIT-CFW\n",
      "\n",
      "  Features used Reduced Dimension Space Classification error Accuracy F1-Score\n",
      "0           PCA                     309                 0.01     0.53     0.49\n",
      "1           LDA                     309                 0.01     0.96     0.97\n",
      "2         K-LDA                     309                0.005     0.97     0.97\n",
      "3           VGG                       -                 0.19     0.67     0.63\n",
      "4        Resnet                       -                 0.00     0.98     0.98\n",
      "5  Resnet + LDA                     309                 0.00     1.00     1.00\n",
      "\n",
      "\n",
      "For Yale face database\n",
      "\n",
      "  Features used Dimension Space Classification error Accuracy F1-Score\n",
      "0           PCA              62                 0.01     0.79     0.83\n",
      "1           LDA               8                 0.00     1.00     1.00\n",
      "2         K-LDA               8                 0.00     1.00     1.00\n",
      "3           VGG               -                 0.09     0.67     0.67\n",
      "4        Resnet               -                 0.00     0.97     0.91\n",
      "5  Resnet + LDA              62                 0.00     1.00     1.00\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, classification error, accuracy, f1-score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('For IMFDB\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'K-LDA', 'VGG', 'Resnet', 'Resnet + LDA'],\n",
    "                   'Reduced Dimension Space': ['108', '108', '108', '-', '-', '108'],\n",
    "                   'Classification error': ['0.0', '0.0', '0.0', '0.03', '0.00', '0.00'],\n",
    "                   'Accuracy': ['0.7','0.94','0.95','0.88', '0.95', '1.00' ], \n",
    "                   'F1-Score': ['0.69', '0.93', '0.95', '0.88', '0.95', '1.00']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "print('For IIIT-CFW\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'K-LDA', 'VGG', 'Resnet', 'Resnet + LDA'],\n",
    "                   'Reduced Dimension Space': ['309', '309', '309', '-', '-', '309'],\n",
    "                   'Classification error': ['0.01', '0.01', '0.005', '0.19', '0.00', '0.00'],\n",
    "                   'Accuracy': ['0.53','0.96','0.97','0.67', '0.98', '1.00' ], \n",
    "                   'F1-Score': ['0.49', '0.97', '0.97', '0.63', '0.98', '1.00']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "print('For Yale face database\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'K-LDA', 'VGG', 'Resnet', 'Resnet + LDA'],\n",
    "                   'Dimension Space': ['62', '8', '8', '-', '-', '62'],\n",
    "                   'Classification error': ['0.01', '0.00', '0.00', '0.09', '0.00', '0.00'],\n",
    "                   'Accuracy': ['0.79','1.00','1.00','0.67', '0.97', '1.00' ], \n",
    "                   'F1-Score': ['0.83', '1.00', '1.00', '0.67', '0.91', '1.00']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "# Print the table. (You can use Pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320/320 [==============================] - 0s 391us/step - loss: 1.8604 - accuracy: 0.1281\n",
      "Epoch 2/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.5370 - accuracy: 0.2812\n",
      "Epoch 3/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 1.3126 - accuracy: 0.4719\n",
      "Epoch 4/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 1.1442 - accuracy: 0.5250\n",
      "Epoch 5/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.9904 - accuracy: 0.7063\n",
      "Epoch 6/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.8274 - accuracy: 0.7406\n",
      "Epoch 7/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.6421 - accuracy: 0.8094\n",
      "Epoch 8/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.4874 - accuracy: 0.9531\n",
      "Epoch 9/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.3655 - accuracy: 0.9812\n",
      "Epoch 10/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.2542 - accuracy: 0.9937\n",
      "Epoch 11/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.1737 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0590 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0384 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0253 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "320/320 [==============================] - 0s 55us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 9.9816e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 9.5532e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 9.1485e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 8.7852e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 8.4229e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "320/320 [==============================] - 0s 51us/step - loss: 8.0779e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 7.7767e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "320/320 [==============================] - 0s 49us/step - loss: 7.4890e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 7.2059e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 6.9604e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 6.6959e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 6.4853e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 6.2499e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 6.0547e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "320/320 [==============================] - 0s 45us/step - loss: 5.8632e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 5.6564e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 5.4989e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 5.3221e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 5.1662e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 5.0061e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "320/320 [==============================] - 0s 39us/step - loss: 4.8713e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "320/320 [==============================] - 0s 37us/step - loss: 4.7259e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "320/320 [==============================] - 0s 40us/step - loss: 4.5934e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 4.4748e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 4.3417e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 4.2335e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "320/320 [==============================] - 0s 41us/step - loss: 4.1238e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "320/320 [==============================] - 0s 42us/step - loss: 4.0074e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 3.9072e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 3.8098e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 3.7131e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 3.6218e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 3.5308e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 3.4459e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 42us/step - loss: 3.3696e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "320/320 [==============================] - 0s 50us/step - loss: 3.2894e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 3.2175e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 3.1416e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 3.0684e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "320/320 [==============================] - 0s 48us/step - loss: 3.0005e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "320/320 [==============================] - 0s 57us/step - loss: 2.9337e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 2.8679e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "320/320 [==============================] - 0s 58us/step - loss: 2.8037e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "320/320 [==============================] - 0s 59us/step - loss: 2.7399e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "320/320 [==============================] - 0s 62us/step - loss: 2.6822e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "320/320 [==============================] - 0s 53us/step - loss: 2.6311e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "320/320 [==============================] - 0s 47us/step - loss: 2.5695e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "320/320 [==============================] - 0s 44us/step - loss: 2.5199e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 2.4713e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "320/320 [==============================] - 0s 94us/step - loss: 2.4179e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "320/320 [==============================] - 0s 92us/step - loss: 2.3768e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "320/320 [==============================] - 0s 43us/step - loss: 2.3246e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 2.2761e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "320/320 [==============================] - 0s 56us/step - loss: 2.2340e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "320/320 [==============================] - 0s 46us/step - loss: 2.1937e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "320/320 [==============================] - 0s 52us/step - loss: 2.1567e-04 - accuracy: 1.0000\n",
      "For IMFDB\n",
      "[[11  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0  0]\n",
      " [ 0  0  8  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0 15]]\n",
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "537/537 [==============================] - 0s 271us/step - loss: 1.7843 - accuracy: 0.1676\n",
      "Epoch 2/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 1.4204 - accuracy: 0.6723\n",
      "Epoch 3/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 1.0106 - accuracy: 0.9534\n",
      "Epoch 4/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.4472 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.1486 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0610 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0315 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "537/537 [==============================] - 0s 55us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "537/537 [==============================] - 0s 52us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 9.9609e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 9.5347e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 9.0775e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 8.6428e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 8.2146e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 7.8163e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 7.4588e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 7.1360e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 6.8409e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 6.5773e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 6.3138e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 6.0727e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 5.8511e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 5.6451e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 5.4261e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 5.2481e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 5.0671e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 4.8837e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 4.7290e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 4.5844e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "537/537 [==============================] - 0s 51us/step - loss: 4.4273e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 4.2860e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "537/537 [==============================] - 0s 45us/step - loss: 4.1592e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 4.0288e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 3.9050e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "537/537 [==============================] - 0s 54us/step - loss: 3.7822e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 3.6733e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 3.5666e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 3.4637e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "537/537 [==============================] - 0s 56us/step - loss: 3.3650e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 3.2687e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 3.1788e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 3.0902e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 3.0087e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "537/537 [==============================] - 0s 50us/step - loss: 2.9232e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "537/537 [==============================] - 0s 48us/step - loss: 2.8446e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.7695e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 2.6962e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 2.6230e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "537/537 [==============================] - 0s 53us/step - loss: 2.5589e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 2.4962e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537/537 [==============================] - 0s 44us/step - loss: 2.4300e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 2.3688e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "537/537 [==============================] - 0s 44us/step - loss: 2.3098e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 2.2544e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 2.2084e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.1486e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "537/537 [==============================] - 0s 38us/step - loss: 2.0972e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.0508e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 2.0034e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "537/537 [==============================] - 0s 46us/step - loss: 1.9564e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 1.9122e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "537/537 [==============================] - 0s 41us/step - loss: 1.8680e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 1.8298e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 1.7894e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 1.7500e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "537/537 [==============================] - 0s 47us/step - loss: 1.7151e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 1.6770e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "537/537 [==============================] - 0s 40us/step - loss: 1.6432e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "537/537 [==============================] - 0s 42us/step - loss: 1.6089e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "537/537 [==============================] - 0s 39us/step - loss: 1.5753e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "537/537 [==============================] - 0s 49us/step - loss: 1.5428e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "537/537 [==============================] - 0s 43us/step - loss: 1.5108e-04 - accuracy: 1.0000\n",
      "IIIT-CFW\n",
      "\n",
      "[[14  0  0  0  0  0  0  0]\n",
      " [ 0 10  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0 19  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0]\n",
      " [ 0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0 12  0]\n",
      " [ 0  0  0  0  0  0  0 24]]\n",
      "Dataset shape: (165, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "132/132 [==============================] - 0s 1000us/step - loss: 2.7072 - accuracy: 0.1439\n",
      "Epoch 2/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 2.4569 - accuracy: 0.1439\n",
      "Epoch 3/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 2.2861 - accuracy: 0.1515\n",
      "Epoch 4/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 2.1707 - accuracy: 0.1818\n",
      "Epoch 5/100\n",
      "132/132 [==============================] - 0s 87us/step - loss: 2.0744 - accuracy: 0.2197\n",
      "Epoch 6/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 1.9886 - accuracy: 0.2197\n",
      "Epoch 7/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.9061 - accuracy: 0.2424\n",
      "Epoch 8/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 1.8228 - accuracy: 0.2803\n",
      "Epoch 9/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 1.7427 - accuracy: 0.3030\n",
      "Epoch 10/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 1.6611 - accuracy: 0.3106\n",
      "Epoch 11/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 1.5793 - accuracy: 0.3864\n",
      "Epoch 12/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 1.4967 - accuracy: 0.4091\n",
      "Epoch 13/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 1.4084 - accuracy: 0.4242\n",
      "Epoch 14/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 1.3181 - accuracy: 0.4621\n",
      "Epoch 15/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 1.2258 - accuracy: 0.5227\n",
      "Epoch 16/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 1.1421 - accuracy: 0.5303\n",
      "Epoch 17/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 1.0613 - accuracy: 0.5833\n",
      "Epoch 18/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.9769 - accuracy: 0.6212\n",
      "Epoch 19/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.8925 - accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "132/132 [==============================] - 0s 71us/step - loss: 0.8146 - accuracy: 0.7576\n",
      "Epoch 21/100\n",
      "132/132 [==============================] - 0s 82us/step - loss: 0.7432 - accuracy: 0.8258\n",
      "Epoch 22/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.6663 - accuracy: 0.8561\n",
      "Epoch 23/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.5756 - accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.4966 - accuracy: 0.9470\n",
      "Epoch 25/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.4173 - accuracy: 0.9470\n",
      "Epoch 26/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.3309 - accuracy: 0.9848\n",
      "Epoch 27/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.2532 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "132/132 [==============================] - 0s 54us/step - loss: 0.1927 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "132/132 [==============================] - 0s 64us/step - loss: 0.1461 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.1193 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0708 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0618 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0390 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0327 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "132/132 [==============================] - 0s 86us/step - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "132/132 [==============================] - 0s 76us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "132/132 [==============================] - 0s 56us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "132/132 [==============================] - 0s 59us/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "132/132 [==============================] - 0s 82us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "132/132 [==============================] - 0s 69us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "132/132 [==============================] - 0s 55us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "132/132 [==============================] - 0s 70us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "132/132 [==============================] - 0s 74us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "132/132 [==============================] - 0s 65us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "132/132 [==============================] - 0s 58us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 0s 64us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "132/132 [==============================] - 0s 61us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "132/132 [==============================] - 0s 77us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "132/132 [==============================] - 0s 78us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "132/132 [==============================] - 0s 75us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "132/132 [==============================] - 0s 79us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "132/132 [==============================] - 0s 57us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "132/132 [==============================] - 0s 73us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "132/132 [==============================] - 0s 63us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "132/132 [==============================] - 0s 68us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "132/132 [==============================] - 0s 60us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "132/132 [==============================] - 0s 66us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "132/132 [==============================] - 0s 72us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "132/132 [==============================] - 0s 62us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "132/132 [==============================] - 0s 83us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "132/132 [==============================] - 0s 67us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Yale face database \n",
      "\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 5 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# For each dataset print the confusion matrix for the best model \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#load dataset \n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print('For IMFDB')\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print('IIIT-CFW\\n')\n",
    "print(conf_mat)\n",
    "\n",
    "#load dataset \n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# OneHot \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "y_train = np_utils.to_categorical(encoded_Y)\n",
    "obj = Classifier1(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "#OneHot for pred not needed. It uses \n",
    "conf_mat, class_report = obj.validate(X_test, y_test)\n",
    "print('Yale face database \\n')\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Similiar to 1(b) use t-SNE based visilization of faces?  Does it makesense?  Do you see similar people coming together?or something else?  Can you do visualization datasetwise and combined? Here you will use a popular implementation.(Worth  reading and understanding  t-SNE.  We  will not discuss it in the class and out of scope for this course/exams.\n",
    "\n",
    "I see people in the same class coming together when done dataset wise (although there are some outliers it reasonable). I have done it using various features but LDA (or K-LDA) and Resnet seem to be the best. When datasets are combined together, one can notice that they are formed like concentric circles. IIIT-CFW has the most variance among the datasets while Yale Face Database has the least after applying T-SNE.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x135699a58>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute TSNE for different features and create a scatter plot\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "# xX = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "# X =  # feature \n",
    "k = 2 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "X_TSNE = TSNE(n_components=k).fit_transform(X)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(np.real(X_TSNE[:,0]),np.real(X_TSNE[:,1]),c=y)\n",
    "# Plot the representation in 2d/3d\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Classes\")\n",
    "ax.add_artist(legend1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x133829860>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute TSNE for different features and create a scatter plot\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "# X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "# X =  # feature \n",
    "k = 2 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "X_TSNE = TSNE(n_components=k).fit_transform(X)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(np.real(X_TSNE[:,0]),np.real(X_TSNE[:,1]),c=y)\n",
    "# Plot the representation in 2d/3d\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Classes\")\n",
    "ax.add_artist(legend1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (165, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x133893ef0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "# X = get_resnet_features(dirpath)\n",
    "X = get_lda(X,y,7)\n",
    "# X =  # feature \n",
    "k = 2 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "X_TSNE = TSNE(n_components=k).fit_transform(X)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "scatter = ax.scatter(np.real(X_TSNE[:,0]),np.real(X_TSNE[:,1]),c=y)\n",
    "# Plot the representation in 2d/3d\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\n",
    "                    loc=\"lower left\", title=\"Classes\")\n",
    "ax.add_artist(legend1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.`face`  is  used  for  verification.   \n",
    "\n",
    "4(a) How do we formulate the problem using KNN\n",
    "\n",
    "1. Extract one of the given features provided. \n",
    "2. Split the dataset into train and validation. \n",
    "3. On the validation set, check for each datapoint what its k nearest neighbors are. \n",
    "4. Out prediction will be the most number of its nearest neighbours from a class is the datapoints class as well. \n",
    "\n",
    "4(b) How do we analyze the performance ? suggest  the  metrics  (like  accuracy) that is appropriate for this task.\n",
    "\n",
    "___________________________________________________________________\n",
    "Metrics for performace: accuray. But more importantly precision. We have make no mistake if the face is not the correct one. So, even if it is correctbut we are not sure or it is 50-50 we have to reject it. I have extracted and performed KNN on various features but Resnet + KLDA is giving me the best performance.  \n",
    "\n",
    "4(c)Show empirical results  with  all  the  representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerification():\n",
    "    def __init__(self,k,classes):\n",
    "        self.k = k\n",
    "        self.classes = classes\n",
    "    \n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def verify(self,X,class_id):\n",
    "        \"\"\"\n",
    "            Given an input X find if the class id is correct or not.\n",
    "            \n",
    "            @return verfication_results => N vector containing True or False. \n",
    "                    If the class-id matches with your prediction then true else false.   \n",
    "        \"\"\"\n",
    "        verif = False\n",
    "        dist = np.zeros(self.X_train.shape[0],)\n",
    "        cnt = 0\n",
    "        z=0\n",
    "        freq = np.zeros(self.classes,)\n",
    "        sort = np.zeros(self.X_train.shape[0],)\n",
    "        for j in range(self.X_train.shape[0]): #for every training data \n",
    "            dist[z] = np.linalg.norm(self.X_train[j,:]-X[:]) # euclidean distance \n",
    "            z = z+1\n",
    "        sort = np.argsort(dist)\n",
    "        maxi = 0\n",
    "        for k in range(self.k):\n",
    "            freq[int(self.y_train[sort[k]])] += 1\n",
    "        pred = np.argmax(freq)\n",
    "        print(pred)\n",
    "        print(class_id)\n",
    "        if int(class_id) == int(pred):\n",
    "            verif = True\n",
    "#             self.verification_results += 1\n",
    "        else:\n",
    "            verif = False\n",
    "#             self.verification_results = 0\n",
    "        verfication_results = verif\n",
    "        return verfication_results\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your verification system will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "            \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.X_train = X_train \n",
    "        self.y_train = y_train \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is your system on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "#         dist = np.zeros(np.shape(self.X_train[0]),)\n",
    "        dist = np.zeros(self.X_train.shape[0],)\n",
    "        cnt = 0\n",
    "        predlist = []\n",
    "        for i in range(X_validate.shape[0]):\n",
    "            z=0\n",
    "            freq = np.zeros(self.classes,)\n",
    "            sort = np.zeros(self.X_train.shape[0],)\n",
    "            for j in range(self.X_train.shape[0]): #for every training data \n",
    "                dist[z] = np.linalg.norm(self.X_train[j,:]-X_validate[i,:]) # euclidean distance \n",
    "                z = z+1\n",
    "            sort = np.argsort(dist)\n",
    "            maxi = 0\n",
    "            for k in range(self.k):\n",
    "                freq[int(self.y_train[sort[k]])] += 1\n",
    "            pred = np.argmax(freq)\n",
    "            predlist.append(pred)\n",
    "            if y_validate[i] == pred:\n",
    "                cnt += 1 \n",
    "#         acc = (cnt/X_validate.shape[0])\n",
    "        classification_report = sk.metrics.classification_report(y_validate, predlist)\n",
    "        return classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       0.92      1.00      0.96        11\n",
      "           3       1.00      0.91      0.95        23\n",
      "           4       1.00      1.00      1.00        25\n",
      "           5       0.94      1.00      0.97        15\n",
      "           6       0.95      1.00      0.97        18\n",
      "           7       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.98       135\n",
      "   macro avg       0.98      0.98      0.97       135\n",
      "weighted avg       0.98      0.98      0.98       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n",
      "IMFDB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       0.86      1.00      0.92         6\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       1.00      1.00      1.00        15\n",
      "           6       1.00      1.00      1.00        14\n",
      "           7       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.99        80\n",
      "   macro avg       0.98      0.99      0.98        80\n",
      "weighted avg       0.99      0.99      0.99        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         5\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       1.00      1.00      1.00         1\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         2\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# LDA \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20        14\n",
      "           1       0.75      0.30      0.43        10\n",
      "           2       0.12      0.89      0.22         9\n",
      "           3       0.34      0.46      0.39        24\n",
      "           4       0.39      0.35      0.37        20\n",
      "           5       1.00      0.10      0.17        21\n",
      "           6       0.50      0.31      0.38        13\n",
      "           7       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.27       135\n",
      "   macro avg       0.43      0.32      0.27       135\n",
      "weighted avg       0.42      0.27      0.26       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n",
      "IMFDB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56         9\n",
      "           1       0.29      0.45      0.36        11\n",
      "           2       0.29      0.64      0.40        11\n",
      "           3       1.00      0.11      0.20         9\n",
      "           4       0.75      0.30      0.43        10\n",
      "           5       0.86      1.00      0.92         6\n",
      "           6       0.67      0.20      0.31        10\n",
      "           7       1.00      0.07      0.13        14\n",
      "\n",
      "    accuracy                           0.42        80\n",
      "   macro avg       0.66      0.47      0.41        80\n",
      "weighted avg       0.65      0.42      0.37        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.40      1.00      0.57         2\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       1.00      0.25      0.40         4\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       0.67      1.00      0.80         2\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       1.00      1.00      1.00         1\n",
      "          13       1.00      0.75      0.86         4\n",
      "          14       1.00      0.50      0.67         4\n",
      "\n",
      "    accuracy                           0.79        33\n",
      "   macro avg       0.81      0.80      0.77        33\n",
      "weighted avg       0.90      0.79      0.79        33\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# PCA\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,309)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,108)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_pca(X,62)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      0.89      0.94        19\n",
      "           4       0.95      0.95      0.95        21\n",
      "           5       0.96      1.00      0.98        22\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.96       135\n",
      "   macro avg       0.95      0.95      0.95       135\n",
      "weighted avg       0.96      0.96      0.96       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n",
      "IMFDB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.78      0.88      0.82         8\n",
      "           2       1.00      1.00      1.00        13\n",
      "           3       1.00      0.82      0.90        17\n",
      "           4       0.88      1.00      0.93         7\n",
      "           5       0.75      1.00      0.86         6\n",
      "           6       1.00      0.92      0.96        12\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.93      0.95      0.93        80\n",
      "weighted avg       0.95      0.94      0.94        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      0.50      0.67         2\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         4\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.97      0.97      0.96        33\n",
      "weighted avg       0.98      0.97      0.97        33\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# Resnet \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        23\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      0.94      0.97        18\n",
      "           5       0.94      1.00      0.97        15\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.98      0.98      0.98       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n",
      "IMFDB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.88      0.78      0.82         9\n",
      "           2       1.00      0.83      0.91         6\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       0.93      1.00      0.97        14\n",
      "           5       1.00      1.00      1.00        12\n",
      "           6       1.00      1.00      1.00         9\n",
      "           7       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.97      0.95      0.96        80\n",
      "weighted avg       0.96      0.96      0.96        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         2\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       1.00      1.00      1.00         2\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# KLDA\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         7\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        18\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00       135\n",
      "   macro avg       1.00      1.00      1.00       135\n",
      "weighted avg       1.00      1.00      1.00       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMFDB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00         8\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       1.00      1.00      1.00        10\n",
      "           7       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         3\n",
      "          10       1.00      1.00      1.00         2\n",
      "          11       1.00      1.00      1.00         3\n",
      "          13       1.00      1.00      1.00         5\n",
      "          14       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# Resnet + KLDA\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_resnet_features(dirpath)\n",
    "X = get_kernel_lda(X,y,7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# print(np.shape(X_train))\n",
    "# print(np.shape(X_test))\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n",
      "IIIT-CFW\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.48        10\n",
      "           1       0.67      0.25      0.36         8\n",
      "           2       0.40      0.55      0.46        11\n",
      "           3       1.00      0.81      0.89        26\n",
      "           4       0.60      0.65      0.63        23\n",
      "           5       0.88      0.88      0.88        16\n",
      "           6       1.00      0.91      0.95        22\n",
      "           7       0.71      0.89      0.79        19\n",
      "\n",
      "    accuracy                           0.74       135\n",
      "   macro avg       0.71      0.68      0.68       135\n",
      "weighted avg       0.77      0.74      0.74       135\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (400, 32, 32)\n",
      "IMFDB\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91         5\n",
      "           1       0.90      0.75      0.82        12\n",
      "           2       0.71      0.83      0.77         6\n",
      "           3       0.73      0.89      0.80         9\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       0.92      0.92      0.92        13\n",
      "           6       1.00      1.00      1.00        13\n",
      "           7       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.90        80\n",
      "   macro avg       0.89      0.90      0.89        80\n",
      "weighted avg       0.91      0.90      0.90        80\n",
      "\n",
      "\n",
      "\n",
      "Dataset shape: (165, 32, 32)\n",
      "Yale Face Database\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       0.50      0.20      0.29         5\n",
      "           5       0.33      1.00      0.50         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.50      0.33      0.40         3\n",
      "           8       0.00      0.00      0.00         3\n",
      "          11       0.40      1.00      0.57         2\n",
      "          12       1.00      1.00      1.00         3\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.52        33\n",
      "   macro avg       0.50      0.51      0.47        33\n",
      "weighted avg       0.57      0.52      0.51        33\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create a train and validation split and show your results \n",
    "\n",
    "# VGG \n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IIIT-CFW\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/IMFDB/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "obj=FaceVerification(9,8)\n",
    "obj.train(X_train, y_train)\n",
    "print('IMFDB\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')\n",
    "\n",
    "dirpath = './dataset/Yale_face_database/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))\n",
    "X = get_vgg_features(dirpath)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "obj=FaceVerification(9,15)\n",
    "obj.train(X_train, y_train)\n",
    "print('Yale Face Database\\n')\n",
    "print(obj.validate(X_test,y_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For IIIT-CFW\n",
      "\n",
      "    Features used Dimension Space Classification error Accuracy F1-Score\n",
      "0             PCA             108                 0.68     0.32     0.30\n",
      "1             LDA               7                 0.06     0.94     0.93\n",
      "2          Resnet               7                 0.01     0.99     0.98\n",
      "3           K-LDA               -                 0.04     0.96     0.94\n",
      "4  Resnet + K-LDA               7                 0.00     1.00     1.00\n",
      "5             VGG               -                 0.33     0.67     0.59\n",
      "\n",
      "\n",
      "For IMFDB\n",
      "\n",
      "    Features used Dimension Space Classification error Accuracy F1-Score\n",
      "0             PCA             309                 0.44     0.56     0.54\n",
      "1             LDA               7                 0.03     0.97     0.98\n",
      "2          Resnet               7                 0.05     0.95     0.95\n",
      "3           K-LDA               -                 0.01     0.99     0.98\n",
      "4  Resnet + K-LDA               7                 0.00     1.00     1.00\n",
      "5             VGG               -                 0.07     0.93     0.93\n",
      "\n",
      "\n",
      "For Yale face database\n",
      "\n",
      "    Features used Dimension Space Classification error Accuracy F1-Score\n",
      "0             PCA              62                 0.27     0.73     0.64\n",
      "1             LDA               7                 0.03     0.97     0.97\n",
      "2          Resnet               7                 0.00     1.00     1.00\n",
      "3           K-LDA               -                 0.03     0.97     0.97\n",
      "4  Resnet + K-LDA               7                 0.00     1.00     1.00\n",
      "5             VGG               -                 0.48     0.52     0.48\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, verification error, accuracy, precision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print('For IIIT-CFW\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'Resnet','K-LDA', 'Resnet + K-LDA', 'VGG'],\n",
    "                   'Dimension Space': ['108', '7', '7', '-', '7', '-'],\n",
    "                   'Classification error': ['0.68', '0.06', '0.01', '0.04', '0.00', '0.33'],\n",
    "                   'Accuracy': ['0.32','0.94','0.99','0.96', '1.00', '0.67' ], \n",
    "                   'F1-Score': ['0.30', '0.93', '0.98', '0.94', '1.00', '0.59']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "print('For IMFDB\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'Resnet','K-LDA', 'Resnet + K-LDA', 'VGG'],\n",
    "                   'Dimension Space': ['309', '7', '7', '-','7', '-'],\n",
    "                   'Classification error': ['0.44', '0.03', '0.05', '0.01', '0.00', '0.07'],\n",
    "                   'Accuracy': ['0.56','0.97','0.95','0.99', '1.00', '0.93' ], \n",
    "                   'F1-Score': ['0.54', '0.98', '0.95', '0.98', '1.00', '0.93']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "print('For Yale face database\\n')\n",
    "df2 = pd.DataFrame({'Features used': ['PCA', 'LDA', 'Resnet','K-LDA', 'Resnet + K-LDA', 'VGG'],\n",
    "                   'Dimension Space': ['62', '7', '7', '-','7','-'],\n",
    "                   'Classification error': ['0.27', '0.03', '0.00', '0.03', '0.00', '0.48'],\n",
    "                   'Accuracy': ['0.73','0.97','1.00','0.97', '1.00', '0.52' ], \n",
    "                   'F1-Score': ['0.64', '0.97', '1.00', '0.97', '1.00', '0.48']})\n",
    "print(df2)\n",
    "print('\\n')\n",
    "# Print the table. (You can use Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extention / Application\n",
    "    Create a system for any one of the following problems:\n",
    "\n",
    "- Politicians  vs  Filmstars  in  a  public  data  set.   (eg.LFW)\n",
    "        You already have seen IIIT-CFW dataset. Use it for classification. \n",
    "        Chose this. I have shown Accuracy, Precision, F1 Scores. I have also shown the confusion matrix below my classification report for further understanding of the data. \n",
    "- Age prediction\n",
    "        Given different actors/actress in IMFDB create new labels based on their age.  \n",
    "- Gender prediction\n",
    "        Given different actors/actress in IMFDB+IIIT-CFW create new labels based on their gender.\n",
    "- Emotion classification\n",
    "        Both the yale dataset and IMFDB contain an `emotion.txt` file. Using that you can create a emotion predicter \n",
    "- cartoon vs real images\n",
    "        Use a combination of IIIT-CFW and other dataset. \n",
    "        \n",
    "\n",
    "\n",
    "You are free to use a new dataset that is publicly available or even create one by crawling from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (672, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]\n",
    "X = X.reshape((N,H*W*C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features\n",
    "X = get_resnet_features(dirpath)\n",
    "#splitting data into train and validation \n",
    "# for i in range(len(y)):\n",
    "#     if (y[i]>=0 and y[i]<=2) or y[i]==4:\n",
    "#         y[i] = 1\n",
    "#     else:\n",
    "#         y[i] = 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#11101000 [1 is actor 0 is politician]\n",
    "#changing labels \n",
    "for i in range(len(y_train)):\n",
    "    if (y_train[i]>=0 and y_train[i]<=2) or y_train[i]==4:\n",
    "        y_train[i] = 1\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]>=0 and y_test[i]<=2) or y_test[i]==4:\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your classifier\n",
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "# MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report\n",
    "import sklearn as sk\n",
    "class E_Classifier():\n",
    "    def __init__(self, X_train):\n",
    "#         super.__init__()\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=X_train.shape[1], activation='relu'))# layer 1 neuron 1000\n",
    "        model.add(Dense(20, activation='relu'))# layer 2 neuron 1000\n",
    "        model.add(Dense(1, activation='sigmoid'))# output layer\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        self.model = model\n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    def verify(self,X_validate,y_true):\n",
    "        \"\"\"\n",
    "            Given an input X find if the class id is correct or not.\n",
    "            \n",
    "            @return verfication_results => N vector containing True or False. \n",
    "                    If the class-id matches with your prediction then true else false.   \n",
    "        \"\"\"\n",
    "        verif = False\n",
    "        y_pred = self.model.predict_classes(X_validate[0,:])\n",
    "        if int(y_true) == int(y_pred):\n",
    "            verif = True\n",
    "        else:\n",
    "            verif = False\n",
    "        verfication_results = verif\n",
    "        return verfication_results\n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        predict = model.predict(X)\n",
    "        return prediction\n",
    "        \n",
    "    def confusion_matrix(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or classifier) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        confusion_matrix = sk.metrics.confusion_matrix(y, pred)\n",
    "        return confusion_matrix\n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        self.model.fit(X_train, y_train,epochs=10)\n",
    "    def retacc(self, X_validate, y_validate):\n",
    "        y_pred = self.model.predict_classes(X_validate)\n",
    "        acc = sk.metrics.accuracy_score(y_validate,y_pred)\n",
    "        return acc\n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        y_pred = self.model.predict_classes(X_validate)\n",
    "        # Create a confusion matrix\n",
    "        confusion_matrix = self.confusion_matrix(y_pred, y_validate)\n",
    "        # Calculate Validation accuracy \n",
    "        # Calculate precision and recall \n",
    "        # Calculate F1-score \n",
    "        classification_report = sk.metrics.classification_report(y_validate, y_pred)\n",
    "        return confusion_matrix, classification_report\n",
    "# Validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "537/537 [==============================] - 0s 280us/step - loss: 0.3196 - accuracy: 0.8883\n",
      "Epoch 2/10\n",
      "537/537 [==============================] - 0s 69us/step - loss: 0.0546 - accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "537/537 [==============================] - 0s 68us/step - loss: 0.0374 - accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "537/537 [==============================] - 0s 67us/step - loss: 0.0306 - accuracy: 0.9907\n",
      "Epoch 5/10\n",
      "537/537 [==============================] - 0s 65us/step - loss: 0.0278 - accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0251 - accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0242 - accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "537/537 [==============================] - 0s 68us/step - loss: 0.0219 - accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0180 - accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "537/537 [==============================] - 0s 69us/step - loss: 0.0202 - accuracy: 0.9888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        74\n",
      "           1       1.00      0.98      0.99        61\n",
      "\n",
      "    accuracy                           0.99       135\n",
      "   macro avg       0.99      0.99      0.99       135\n",
      "weighted avg       0.99      0.99      0.99       135\n",
      "\n",
      "[[74  0]\n",
      " [ 1 60]]\n"
     ]
    }
   ],
   "source": [
    "obj = E_Classifier(X_train)\n",
    "obj.train(X_train, y_train)\n",
    "conf_mat, class_rep = obj.validate(X_test, y_test)\n",
    "print(class_rep)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features\n",
    "X = get_resnet_features(dirpath)\n",
    "#splitting data into train and validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "#11101000 [1 is actor 0 is politician]\n",
    "#changing labels \n",
    "for i in range(len(y_train)):\n",
    "    if (y_train[i]>=0 and y_train[i]<=2) or y_train[i]==4:\n",
    "        y_train[i] = 1\n",
    "    else:\n",
    "        y_train[i] = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i]>=0 and y_test[i]<=2) or y_test[i]==4:\n",
    "        y_test[i] = 1\n",
    "    else:\n",
    "        y_test[i] = 0\n",
    "for i in range(len(y)):\n",
    "    if (y[i]>=0 and y[i]<=2) or y[i]==4:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "537/537 [==============================] - 0s 296us/step - loss: 0.2254 - accuracy: 0.9479\n",
      "Epoch 2/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0433 - accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "537/537 [==============================] - 0s 69us/step - loss: 0.0414 - accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "537/537 [==============================] - 0s 70us/step - loss: 0.0375 - accuracy: 0.9870\n",
      "Epoch 5/10\n",
      "537/537 [==============================] - 0s 63us/step - loss: 0.0342 - accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0331 - accuracy: 0.9870\n",
      "Epoch 7/10\n",
      "537/537 [==============================] - 0s 64us/step - loss: 0.0294 - accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "537/537 [==============================] - 0s 63us/step - loss: 0.0290 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "537/537 [==============================] - 0s 63us/step - loss: 0.0283 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "537/537 [==============================] - 0s 57us/step - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 1/10\n",
      "537/537 [==============================] - 0s 271us/step - loss: 0.1399 - accuracy: 0.9423\n",
      "Epoch 2/10\n",
      "537/537 [==============================] - 0s 64us/step - loss: 0.0159 - accuracy: 0.9963\n",
      "Epoch 3/10\n",
      "537/537 [==============================] - 0s 67us/step - loss: 0.0107 - accuracy: 0.9963\n",
      "Epoch 4/10\n",
      "537/537 [==============================] - 0s 63us/step - loss: 0.0091 - accuracy: 0.9963\n",
      "Epoch 5/10\n",
      "537/537 [==============================] - 0s 67us/step - loss: 0.0089 - accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0082 - accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "537/537 [==============================] - 0s 66us/step - loss: 0.0069 - accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "537/537 [==============================] - 0s 60us/step - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "537/537 [==============================] - 0s 62us/step - loss: 0.0056 - accuracy: 0.9963\n",
      "Epoch 10/10\n",
      "537/537 [==============================] - 0s 63us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 1/10\n",
      "538/538 [==============================] - 0s 267us/step - loss: 0.3036 - accuracy: 0.9145\n",
      "Epoch 2/10\n",
      "538/538 [==============================] - 0s 62us/step - loss: 0.0619 - accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "538/538 [==============================] - 0s 65us/step - loss: 0.0458 - accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "538/538 [==============================] - 0s 65us/step - loss: 0.0396 - accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "538/538 [==============================] - 0s 62us/step - loss: 0.0381 - accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "538/538 [==============================] - 0s 63us/step - loss: 0.0350 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "538/538 [==============================] - 0s 67us/step - loss: 0.0344 - accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "538/538 [==============================] - 0s 64us/step - loss: 0.0335 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "538/538 [==============================] - 0s 63us/step - loss: 0.0335 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "538/538 [==============================] - 0s 62us/step - loss: 0.0311 - accuracy: 0.9907\n",
      "Epoch 1/10\n",
      "538/538 [==============================] - 0s 272us/step - loss: 0.1921 - accuracy: 0.9368\n",
      "Epoch 2/10\n",
      "538/538 [==============================] - 0s 66us/step - loss: 0.0616 - accuracy: 0.9814\n",
      "Epoch 3/10\n",
      "538/538 [==============================] - 0s 66us/step - loss: 0.0453 - accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "538/538 [==============================] - 0s 64us/step - loss: 0.0431 - accuracy: 0.9851\n",
      "Epoch 5/10\n",
      "538/538 [==============================] - 0s 69us/step - loss: 0.0399 - accuracy: 0.9851\n",
      "Epoch 6/10\n",
      "538/538 [==============================] - 0s 67us/step - loss: 0.0422 - accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "538/538 [==============================] - 0s 62us/step - loss: 0.0372 - accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "538/538 [==============================] - 0s 60us/step - loss: 0.0367 - accuracy: 0.9851\n",
      "Epoch 9/10\n",
      "538/538 [==============================] - 0s 60us/step - loss: 0.0284 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "538/538 [==============================] - 0s 64us/step - loss: 0.0329 - accuracy: 0.9888\n",
      "Epoch 1/10\n",
      "538/538 [==============================] - 0s 267us/step - loss: 0.1715 - accuracy: 0.9535\n",
      "Epoch 2/10\n",
      "538/538 [==============================] - 0s 67us/step - loss: 0.0357 - accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "538/538 [==============================] - 0s 71us/step - loss: 0.0310 - accuracy: 0.9851\n",
      "Epoch 4/10\n",
      "538/538 [==============================] - 0s 67us/step - loss: 0.0338 - accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "538/538 [==============================] - 0s 66us/step - loss: 0.0345 - accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "538/538 [==============================] - 0s 62us/step - loss: 0.0279 - accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "538/538 [==============================] - 0s 61us/step - loss: 0.0316 - accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "538/538 [==============================] - 0s 59us/step - loss: 0.0284 - accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "538/538 [==============================] - 0s 64us/step - loss: 0.0262 - accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "538/538 [==============================] - 0s 64us/step - loss: 0.0269 - accuracy: 0.9907\n",
      "0.7469541182974019\n"
     ]
    }
   ],
   "source": [
    "# Show qualitative results such as accuracy, k-fold validation, TSNE/PCA/Isomap plots, etc.\n",
    "# I have provided accuracy, precision and confusion matrix above. Please look at that. And I am performing K-Fold Validation here \n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "acc = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "     X_train, X_test = X[train_index], X[test_index]\n",
    "     y_train, y_test = y[train_index], y[test_index]\n",
    "     obj = E_Classifier(X_train)\n",
    "     obj.train(X_train, y_train)\n",
    "     acc.append(obj.retacc(X_test,y_test))\n",
    "#      print(obj.retacc(X_test,y_test))\n",
    "acc = np.array(acc)\n",
    "print(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantitative results such as examples of correct prediction and wrong prediction\n",
    "# From the confusion matrix we can see that 132 samples have been correctly classified and 3 have been wrongly classified.\n",
    "# That is the quantitative result.\n",
    "# Couldnt find an example which is classified wrongly manually cause the classifier's accuracy is so high "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
